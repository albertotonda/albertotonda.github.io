---
title: Deep learning in practice with pytorch
summary: Class on deep learning for Ph.D. students enrolled in Universit√© Paris-Saclay, taught in English 
date: 2023-01-01
type: docs
math: false
tags:
  - deep learning
  - pytorch
  - teaching
image:
  image:
  caption: 'Embed rich media such as videos and LaTeX math'
---

The aim of this class is to provide students with a hands-on approach to deep learning, exploring functionalities of the pytorch library. Different applications of deep learning to relational data such as images and time sequences will presented, including the description of architectures like convolutional neural networks, recurrent neural networks, autoencoders, and transformers.

## Summary of basic Machine Learning concepts
The first session is an introduction to the class and a (relatively quick) summary of basic machine learning concepts that will be extensively used in the following. 

Google Colaboratory notebook with exercises: (requires a Google account): https://colab.research.google.com/drive/1a5418oFw2pHwyALxXP1cqfAQfT76_8f5?usp=sharing

## Basics of pytorch
Introduction to basic concepts of pytorch. Tensors, Modules, Optimizers, Loss functions.

Google Colaboratory notebook with exercises: https://colab.research.google.com/drive/146pua5hpN8DcF958TaDqq3rO1tEgjX9h?usp=sharing

## Intermediate pytorch concepts
Slightly more advanced pytorch concepts. Monitoring training performance, using Tensorboard, Stochastic gradient descent and derived techniques, Schedulers, Activation functions, Checkpointing.

Google Colaboratory notebook with exercises: https://colab.research.google.com/drive/1RuT7FiEWVSgUF_aaSr8CIZCB6bEKV20R?usp=sharing

## Convolutional neural networks
1. Basics of Convolutional Neural Networks (CNNs): convolution, pooling, architectures, applications.
2. An example applied to RNA/cDNA for classification.

Google Colaboratory notebook with exercises on CNNs: https://colab.research.google.com/drive/1tSJZqGKw5EAuhUwG1ZTfB8ZeBa3VjqSi?usp=sharing

## Regularization and remarks
Quick excerpt on regularization techniques and a first set of remarks on Deep Learning

## Visualization techniques for CNNs
An overview of visualization techniques for CNNs.

Colaboratory notebook with exercises: https://colab.research.google.com/drive/1k7hYg21Z6J8qh2f-jOmdWSljxXikTjW6?usp=sharing

## Embeddings
Basic notions of embeddings: what they are, and how to create them. Example of word embeddings with Word2Vec.

## Recurrent neural networks
Recurrent Neural Networks (RNNs) and more modern architectures, such as Long-Short-Term Memory Networks (LSTMs) and Gated Recurrent Units (GRUs).

Colaboratory notebook: https://colab.research.google.com/drive/19RlceOejtIE_Ecn5kFPjEaXUrkdhO7YB?usp=sharing

## Sequence to sequence
Introduction to the seq2seq architecture.

Colaboratory notebook with exercises: https://colab.research.google.com/drive/18ODB9ae2lkugSMUZw56KAlhBnlPVR7JX?usp=sharing

## Attention and Transformers
Attention module and Transformer architectures.

## Concept bottleneck models
Introduction to Concept Bottleneck Models and Concept Embedding Models.

## Relational concept bottleneck models
Advanced seminar on relational concept bottleneck models, given by [Dr. Pietro Barbiero](https://www.pietrobarbiero.eu/).