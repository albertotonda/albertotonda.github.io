@inproceedings{squillero2008anovel,
  doi = {10.1145/1388969.1389049},
  url = {https://doi.org/10.1145/1388969.1389049},
  year = {2008},
  publisher = {{ACM} Press},
  author = {Giovanni Squillero and Alberto Tonda},
  title = {A novel methodology for diversity preservation in evolutionary algorithms},
  booktitle = {Proceedings of the 2008 {GECCO} conference companion on Genetic and evolutionary computation - {GECCO} {\textquotesingle}08},
  abstract = {In this paper we describe an improvement of an entropy-based diversity preservation approach for evolutionary algorithms. This approach exploits the information contained not only in the parts that compose an individual, but also in their position and relative order. We executed a set of preliminary experiments in order to test the new approach, using two different problems in which diversity preservation plays a major role in obtaining good solutions.}
}

@inproceedings{perez2009onthegeneration,
  doi = {10.1109/ats.2009.37},
  url = {https://doi.org/10.1109/ats.2009.37},
  year = {2009},
  publisher = {{IEEE}},
  author = {W. J. Perez H. and Danilo Ravotto and Ernesto Sanchez and Matteo Sonza Reorda and Alberto Tonda},
  title = {On the Generation of Functional Test Programs for the Cache Replacement Logic},
  booktitle = {2009 Asian Test Symposium},
  abstract = {Caches are crucial components in modern processors (both stand-alone or integrated into SoCs) and their test is a challenging task, especially when addressing complex and high-frequency devices. While the test of the memory array within the cache is usually accomplished resorting to BIST circuitry implementing March test inspired solutions, testing the cache controller logic poses some specific issues, mainly stemming from its limited accessibility. One possible solution consists in letting the processor execute suitable test programs, allowing the detection of possible faults by looking at the results they produce. In this paper we face the issue of generating suitable programs for testing the replacement logic in set-associative caches that implement a deterministic replacement policy. A test program generation approach based on modeling the replacement mechanism as a finite state machine (FSM) is proposed. Experimental results with a cache implementing a LRU policy are provided to assess the effectiveness of the method.}
}

@inproceedings{gandini2009automatic,
  doi = {10.1145/1569901.1570238},
  url = {https://doi.org/10.1145/1569901.1570238},
  year = {2009},
  publisher = {{ACM} Press},
  author = {Sergio Gandini and Danilo Ravotto and Walter Ruzzarin and Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Automatic detection of software defects},
  booktitle = {Proceedings of the 11th Annual conference on Genetic and evolutionary computation - {GECCO} {\textquotesingle}09},
  abstract = {Mobile phones are becoming more and more complex devices, both from the hardware and from the software point of view. Consequently, their various parts are often developed separately. Each sub-system or application may be worked out by a specialized team of engineers and programmers. Frequently, bugs in one component are triggered by the complex interaction between the different applications. Those errors sometimes lead to power dissipation and other misbehaviors that lower residual battery life, a catastrophic event from the user perspective. In this paper we propose a model-based automatic approach to uncover software bugs, which is intended to complement human expertise and complete a qualifying verification plan. The system has been applied on the prototype of a Motorola mobile phone during a partnership with Politecnico di Torino. We demonstrate that our approach is effective by detecting three distinct software misbehaviours that escape all traditional tests. The paper details the methodology, tests and results.}
}

@inproceedings{dicarlo2010towards,
  doi = {10.1145/1830483.1830727},
  url = {https://doi.org/10.1145/1830483.1830727},
  year = {2010},
  publisher = {{ACM} Press},
  author = {Stefano Di Carlo and Ernesto Sanchez and Alberto Scionti and Giovanni Squillero and Alberto Paolo Tonda and Matteo Falasconi},
  title = {Towards drift correction in chemical sensors using an evolutionary strategy},
  booktitle = {Proceedings of the 12th annual conference on Genetic and evolutionary computation - {GECCO} {\textquotesingle}10},
  abstract = {Gas chemical sensors are strongly affected by the so-called drift, i.e., changes in sensors' response caused by poisoning and aging that may significantly spoil the measures gathered. The paper presents a mechanism able to correct drift, that is: delivering a correct unbiased fingerprint to the end user. The proposed system exploits a state-of-the-art evolutionary strategy to iteratively tweak the coefficients of a linear transformation. The system operates continuously. The optimal correction strategy is learnt without a-priori models or other hypothesis on the behavior of physical-chemical sensors. Experimental results demonstrate the efficacy of the approach on a real problem.}
}

@incollection{sanchez2010evolving,
  doi = {10.1007/978-3-642-12239-2_2},
  url = {https://doi.org/10.1007/978-3-642-12239-2_2},
  year = {2010},
  publisher = {Springer Berlin Heidelberg},
  pages = {11--20},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Evolving Individual Behavior in a Multi-agent Traffic Simulator},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {In this paper, we illustrate the use of evolutionary agents in a multi-agent system designed to describe the behavior of car drivers. Each agent has the selfish objective to reach its destination in the shortest time possible, and a preference in terms of paths to take, based on the presence of other agents and on the width of the roads. Those parameters are changed with an evolutionary strategy, to mimic the adaptation of a human driver to different traffic conditions. The system proposed is then tested by giving the agents the ability to perceive the presence of other agents in a given radius. Experimental results show that knowing the position of all the car drivers in the map leads the agents to obtain a better performance, thanks to the evolution of their behavior. Even the system as a whole gains some benefits from the evolution of the agents' individual choices.}
}

@incollection{dicarlo2010exploiting,
  doi = {10.1007/978-3-642-12239-2_43},
  url = {https://doi.org/10.1007/978-3-642-12239-2_43},
  year = {2010},
  publisher = {Springer Berlin Heidelberg},
  pages = {412--421},
  author = {Stefano Di Carlo and Matteo Falasconi and Ernesto S{\'{a}}nchez and Alberto Scionti and Giovanni Squillero and Alberto Tonda},
  title = {Exploiting Evolution for an Adaptive Drift-Robust Classifier in Chemical Sensing},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {Gas chemical sensors are strongly affected by drift, i.e., changes in sensors’ response with time, that may turn statistical models commonly used for classification completely useless after a period of time. This paper presents a new classifier that embeds an adaptive stage able to reduce drift effects. The proposed system exploits a state-of-the-art evolutionary strategy to iteratively tweak the coefficients of a linear transformation able to transparently transform raw measures in order to mitigate the negative effects of the drift. The system operates continuously. The optimal correction strategy is learnt without a-priori models or other hypothesis on the behavior of physical-chemical sensors. Experimental results demonstrate the efficacy of the approach on a real problem.}
}

@inproceedings{perez2011functional,
  doi = {10.1109/latw.2011.5985898},
  url = {https://doi.org/10.1109/latw.2011.5985898},
  year = {2011},
  month = mar,
  publisher = {{IEEE}},
  author = {W. J. H. Perez and Ernesto Sanchez and Matteo Sonza Reorda and Alberto Tonda and Juan Velasco Medina},
  title = {Functional Test Generation for the {pLRU} Replacement Mechanism of Embedded Cache Memories},
  booktitle = {2011 12th Latin American Test Workshop ({LATW})},
  abstract = {Testing cache memories is a challenging task, especially when targeting complex and high-frequency devices such as modern processors. While the memory array in a cache is usually tested exploiting BIST circuits that implement March-based solutions, there is no established methodology to tackle the cache controller logic, mainly due to its limited accessibility. One possible approach is Software-Based Self Testing (SBST): however, devising test programs able to thoroughly excite the replacement logic and made the results observable is not trivial. A test program generation approach, based on a Finite State Machine (FSM) model of the replacement mechanism, is proposed in this paper. The effectiveness of the method is assessed on a case study considering a data cache implementing the pLRU replacement policy.}
}

@inproceedings{dicarlo2011covariance,
  doi = {10.1063/1.3626293},
  url = {https://doi.org/10.1063/1.3626293},
  year = {2011},
  publisher = {{AIP}},
  author = {Stefano Di Carlo and Matteo Falasconi and Ernesto Sanchez and Giovanni Sberveglieri and Alberto Scionti and Giovanni Squillero and Alberto Tonda and Perena Gouma},
  title = {Covariance Matrix Adaptation Evolutionary Strategy for Drift Correction of Electronic Nose Data},
  booktitle = {Proceedings of International Symposium on Olfaction and Electronic Nose 2011},
  abstract = {Electronic Noses (ENs) might represent a simple, fast, high sample throughput and economic alternative to conventional analytical instruments. However, gas sensors drift still limits the EN adoption in real industrial setups due to high recalibration effort and cost. In fact, pattern recognition (PaRC) models built in the training phase become useless after a period of time, in some cases a few weeks. Although algorithms to mitigate the drift date back to the early 90 this is still a challenging issue for the chemical sensor community. Among other approaches, adaptive drift correction methods adjust the PaRC model in parallel with data acquisition without need of periodic calibration. Self‐Organizing Maps (SOMs) and Adaptive Resonance Theory (ART) networks have been already tested in the past with fair success. This paper presents and discusses an original methodology based on a Covariance Matrix Adaptation Evolution Strategy (CMA‐ES), suited for stochastic optimization of complex problems.}
}

@inproceedings{sanchez2011group,
  doi = {10.1109/cec.2011.5949951},
  url = {https://doi.org/10.1109/cec.2011.5949951},
  year = {2011},
  month = jun,
  publisher = {{IEEE}},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Group evolution: Emerging synergy through a coordinated effort},
  booktitle = {2011 {IEEE} Congress of Evolutionary Computation ({CEC})},
  abstract = {A huge number of optimization problems, in the CAD area as well as in many other fields, require a solution composed by a set of structurally homogeneous elements. Each element tackles a subset of the original task, and they cumulatively solve the whole problem. Sub-tasks, however, have exactly the same structure, and the splitting is completely arbitrary. Even the number of sub-tasks is not known and cannot be determined a-priori. Individual elements are structurally homogeneous, and their contribution to the main solution can be evaluated separately. We propose an evolutionary algorithm able to optimize groups of individuals for solving this class of problems. An individual of the best solution may be sub-optimal when considered alone, but the set of individuals cumulatively represent the optimal group able to completely solve the whole problem. Results of preliminary experiments show that our algorithm performs better than other techniques commonly applied in the CAD field.}
}

@incollection{sanchez2011evolution,
  doi = {10.1007/978-3-642-20520-0_17},
  url = {https://doi.org/10.1007/978-3-642-20520-0_17},
  year = {2011},
  publisher = {Springer Berlin Heidelberg},
  pages = {162--171},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Evolution of Test Programs Exploiting a {FSM} Processor Model},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {Microprocessor testing is becoming a challenging task, due to the increasing complexity of modern architectures. Nowadays, most architectures are tackled with a combination of scan chains and Software-Based Self-Test (SBST) methodologies. Among SBST techniques, evolutionary feedback-based ones prove effective in microprocessor testing: their main disadvantage, however, is the considerable time required to generate suitable test programs. A novel evolutionary-based approach, able to appreciably reduce the generation time, is presented. The proposed method exploits a high-level representation of the architecture under test and a dynamically built Finite State Machine (FSM) model to assess fault coverage without resorting to time-expensive simulations on low-level models. Experimental results, performed on an OpenRISC processor, show that the resulting test obtains a nearly complete fault coverage against the targeted fault model.}
}

@inproceedings{sanchez2011evolutionary,
  doi = {10.1145/2001858.2001985},
  url = {https://doi.org/10.1145/2001858.2001985},
  year = {2011},
  publisher = {{ACM} Press},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Evolutionary failing-test generation for modern microprocessors},
  booktitle = {Proceedings of the 13th annual conference companion on Genetic and evolutionary computation - {GECCO} {\textquotesingle}11},
  abstract = {The incessant progress in manufacturing technology is posing new challenges to microprocessor designers. Nowadays, comprehensive verification of a chip can only be performed after tape-out, when the first silicon prototypes are available. Several activities that were originally supposed to be part of the pre-silicon design phase are migrating to this post-silicon time as well. The short paper describes a post-silicon methodology that can be exploited to devise functional failing tests. Such tests are essential to analyze and debug speed paths during verification, speed-stepping, and other critical activities. The proposed methodology is based on the Genetic Programming paradigm, and exploits a versatile toolkit named μGP. The paper demonstrates that an evolutionary algorithm can successfully tackle a significant and still open industrial problem. Moreover, it shows how to take into account complex hardware characteristics and architectural details of such complex devices.}
}

@inproceedings{sanchez2011onthefunctional,
  doi = {10.1109/vlsisoc.2011.6081650},
  url = {https://doi.org/10.1109/vlsisoc.2011.6081650},
  year = {2011},
  month = oct,
  publisher = {{IEEE}},
  author = {Ernesto Sanchez and Matteo Sonza Reorda and Alberto Tonda},
  title = {On the functional test of Branch Prediction Units based on Branch History Table},
  booktitle = {2011 {IEEE}/{IFIP} 19th International Conference on {VLSI} and System-on-Chip},
  abstract = {Branch Prediction Units (BPUs) are highly efficient modules that can significantly decrease the negative impact of branches in superscalar and RISC processors. Traditional test solutions, mainly based on scan test, are often inadequate to tackle the complexity of these architectures, especially when dealing with delay faults that require at-speed stimuli application. Moreover, scan test does not represent a viable solution when Incoming Inspection or on-line test are considered. In this paper a functional approach targeting BPU test is proposed, allowing to generate a suitable test program whose effectiveness is independent on the specific implementation of the BPU. The effectiveness of the approach is validated on a Branch History Table (BHT) resorting to an open-source computer architecture simulator and to an ad hoc developed HDL testbench. Experimental results show that the proposed method is able to thoroughly test the BHT, reaching complete static fault coverage.}
}

@inproceedings{sanchez2011postsilicon,
  doi = {10.1109/vlsisoc.2011.6081667},
  url = {https://doi.org/10.1109/vlsisoc.2011.6081667},
  year = {2011},
  month = oct,
  publisher = {{IEEE}},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Post-silicon failing-test generation through evolutionary computation},
  booktitle = {2011 {IEEE}/{IFIP} 19th International Conference on {VLSI} and System-on-Chip},
  abstract = {The incessant progress in manufacturing technology is posing new challenges to microprocessor designers. Several activities that were originally supposed to be part of the pre-silicon design phase are migrating after tape-out, when the first silicon prototypes are available. The paper describes a post-silicon methodology for devising functional failing tests. Therefore, suited to be exploited by microprocessor producer to detect, analyze and debug speed paths during verification, speed-stepping, or other critical activities. The proposed methodology is based on an evolutionary algorithm and exploits a versatile toolkit named μGP. The paper describes how to take into account complex hardware characteristics and architectural details of such complex devices. The experimental evaluation clearly demonstrates the potential of this line of research.}
}

@incollection{tonda2011lamps,
  doi = {10.1007/978-3-642-24094-2_7},
  url = {https://doi.org/10.1007/978-3-642-24094-2_7},
  year = {2011},
  publisher = {Springer Berlin Heidelberg},
  pages = {101--120},
  author = {Alberto Tonda and Evelyne Lutton and Giovanni Squillero},
  title = {Lamps: A Test Problem for Cooperative Coevolution},
  booktitle = {Nature Inspired Cooperative Strategies for Optimization ({NICSO} 2011)},
  abstract = {We present an analysis of the behaviour of Cooperative Co-evolution algorithms (CCEAs) on a simple test problem, that is the optimal placement of a set of lamps in a square room, for various problems sizes. Cooperative Co-evolution makes it possible to exploit more efficiently the artificial Darwinism scheme, as soon as it is possible to turn the optimisation problem into a co-evolution of interdependent sub-parts of the searched solution. We show here how two cooperative strategies, Group Evolution (GE) and Parisian Evolution (PE) can be built for the lamps problem. An experimental analysis then compares a classical evolution to GE and PE, and analyses their behaviour with respect to scale.}
}

@inproceedings{sanchez2011automatic,
  doi = {10.1109/mtv.2011.19},
  url = {https://doi.org/10.1109/mtv.2011.19},
  year = {2011},
  month = dec,
  publisher = {{IEEE}},
  author = {Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Automatic Generation of Software-based Functional Failing Test for Speed Debug and On-silicon Timing Verification},
  booktitle = {2011 12th International Workshop on Microprocessor Test and Verification},
  abstract = {The 40 years since the appearance of the Intel 4004 deeply changed how microprocessors are designed. Today, essential steps in the validation process are performed relying on physical dices, analyzing the actual behavior under appropriate stimuli. This paper presents a methodology that can be used to devise assembly programs suitable for a range of on-silicon activities, like speed debug, timing verification or speed binning. The methodology is fully automatic. It exploits the feedback from the microprocessor under examination and does not rely on information about its microarchitecture, nor does it require design-for-debug features. The experimental evaluation performed on a Intel Pentium Core i7-950 demonstrates the feasibility of the approach.}
}

@incollection{tonda2012bayesian,
  doi = {10.1007/978-3-642-29139-5_22},
  url = {https://doi.org/10.1007/978-3-642-29139-5_22},
  year = {2012},
  publisher = {Springer Berlin Heidelberg},
  pages = {254--265},
  author = {Alberto Paolo Tonda and Evelyne Lutton and Romain Reuillon and Giovanni Squillero and Pierre-Henri Wuillemin},
  title = {Bayesian Network Structure Learning from Limited Datasets through Graph Evolution},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {Bayesian networks are stochastic models, widely adopted to encode knowledge in several fields. One of the most interesting features of a Bayesian network is the possibility of learning its structure from a set of data, and subsequently use the resulting model to perform new predictions. Structure learning for such models is a NP-hard problem, for which the scientific community developed two main approaches: score-and-search metaheuristics, often evolutionary-based, and dependency-analysis deterministic algorithms, based on stochastic tests. State-of-the-art solutions have been presented in both domains, but all methodologies start from the assumption of having access to large sets of learning data available, often numbering thousands of samples. This is not the case for many real-world applications, especially in the food processing and research industry. This paper proposes an evolutionary approach to the Bayesian structure learning problem, specifically tailored for learning sets of limited size. Falling in the category of score-and-search techniques, the methodology exploits an evolutionary algorithm able to work directly on graph structures, previously used for assembly language generation, and a scoring function based on the Akaike Information Criterion, a well-studied metric of stochastic model performance. Experimental results show that the approach is able to outperform a state-of-the-art dependency-analysis algorithm, providing better models for small datasets.}
}

@inproceedings{ciganda2012automatic,
  doi = {10.1109/mtv.2012.17},
  url = {https://doi.org/10.1109/mtv.2012.17},
  year = {2012},
  month = dec,
  publisher = {{IEEE}},
  author = {Lyl Mercedes Ciganda and Marco Gaudesi and Evelyne Lutton and Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Automatic Generation of On-Line Test Programs through a Cooperation Scheme},
  booktitle = {2012 13th International Workshop on Microprocessor Test and Verification ({MTV})},
  abstract = {Test programs for Software-based Self-Test (SBST) can be exploited during the mission phase of microprocessor-based systems to periodically assess hardware integrity. However, several additional constraints must be imposed due to the coexistence of test programs with the mission application. This paper proposes a method for the generation of SBST on-line test programs for embedded RISC processors, systems where the impact of on-line constraints is significant. The proposed strategy exploits an evolutionary optimizer that is able to create a complete test set of programs relying on a new cooperative scheme. Experimental results showed high fault coverage values on two different modules of a MIPS-like processor core. These two case studies demonstrate the effectiveness of the technique and the low human effort required for its implementation.}
}

@inproceedings{gaudesi2013evolutionary,
  doi = {10.1145/2480362.2480400},
  url = {https://doi.org/10.1145/2480362.2480400},
  year = {2013},
  publisher = {{ACM} Press},
  author = {Marco Gaudesi and Andrea Marion and Tommaso Musner and Giovanni Squillero and Alberto Tonda},
  title = {Evolutionary optimization of wetlands design},
  booktitle = {Proceedings of the 28th Annual {ACM} Symposium on Applied Computing - {SAC} {\textquotesingle}13},
  abstract = {Wetlands are artificial ponds, designed to filter and purify running water through the contact with plant stems and roots. Wetland layouts are traditionally designed by experts through a laborious and time-consuming procedure: in principle, small patches of vegetation with purifying properties are tentatively placed, then the resulting water flow is verified by fluid dynamics simulators and when a satisfying outcome is reached, the wetland final layout is decided. This paper proposes to automate wetland design exploiting an evolutionary algorithm: a population of candidate solutions is cultivated by the evolutionary core, and their efficiency is evaluated using a state-of-the-art fluid-dynamics simulation framework. Experimental results show that the results obtained by the proposed approach are qualitatively comparable with those provided by experts, despite the complete absence of human intervention during the optimization process.}
}

@incollection{tonda2013amemetic,
  doi = {10.1007/978-3-642-37192-9_11},
  url = {https://doi.org/10.1007/978-3-642-37192-9_11},
  year = {2013},
  publisher = {Springer Berlin Heidelberg},
  pages = {102--111},
  author = {Alberto Tonda and Evelyne Lutton and Giovanni Squillero and Pierre-Henri Wuillemin},
  title = {A Memetic Approach to Bayesian Network Structure Learning},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {Bayesian networks are graphical statistical models that represent inference between data. For their effectiveness and versatility, they are widely adopted to represent knowledge in different domains. Several research lines address the NP-hard problem of Bayesian network structure learning starting from data: over the years, the machine learning community delivered effective heuristics, while different Evolutionary Algorithms have been devised to tackle this complex problem. This paper presents a Memetic Algorithm for Bayesian network structure learning, that combines the exploratory power of an Evolutionary Algorithm with the speed of local search. Experimental results show that the proposed approach is able to outperform state-of-the-art heuristics on two well-studied benchmarks.}
}

@incollection{bucur2013anevolutionary,
  doi = {10.1007/978-3-642-37192-9_1},
  url = {https://doi.org/10.1007/978-3-642-37192-9_1},
  year = {2013},
  publisher = {Springer Berlin Heidelberg},
  pages = {1--11},
  author = {Doina Bucur and Giovanni Iacca and Giovanni Squillero and Alberto Tonda},
  title = {An Evolutionary Framework for Routing Protocol Analysis in Wireless Sensor Networks},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {Wireless Sensor Networks (WSNs) are widely adopted for applications ranging from surveillance to environmental monitoring. While powerful and relatively inexpensive, they are subject to behavioural faults which make them unreliable. Due to the complex interactions between network nodes, it is difficult to uncover faults in a WSN by resorting to formal techniques for verification and analysis, or to testing. This paper proposes an evolutionary framework to detect anomalous behaviour related to energy consumption in WSN routing protocols. Given a collection protocol, the framework creates candidate topologies and evaluates them through simulation on the basis of metrics measuring the radio activity on nodes. Experimental results using the standard Collection Tree Protocol show that the proposed approach is able to unveil topologies plagued by excessive energy depletion over one or more nodes, and thus could be used as an offline debugging tool to understand and correct the issues before network deployment and during the development of new protocols.}
}

@incollection{gaudesi2013anevolutionary,
  doi = {10.1007/978-3-642-37189-9_16},
  url = {https://doi.org/10.1007/978-3-642-37189-9_16},
  year = {2013},
  publisher = {Springer Berlin Heidelberg},
  pages = {177--187},
  author = {Marco Gaudesi and Andrea Marion and Tommaso Musner and Giovanni Squillero and Alberto Tonda},
  title = {An Evolutionary Approach to Wetlands Design},
  booktitle = {Evolutionary Computation,  Machine Learning and Data Mining in Bioinformatics},
  abstract = {Wetlands are artificial basins that exploit the capabilities of some species of plants to purify water from pollutants. The design process is currently long and laborious: such vegetated areas are inserted within the basin by trial and error, since there is no automatic system able to maximize the efficiency in terms of filtering. Only at the end of several attempts, experts are able to determine which is the most convenient configuration and choose up a layout. This paper proposes the use of an evolutionary algorithm to automate both the placement and the sizing of vegetated areas within a basin. The process begins from a random population of solutions and, evaluating their efficiency with an state-of-the-art fluid-dynamics simulation framework, the evolutionary algorithm is able to automatically find optimized solution whose performance are comparable with those achieved by human experts.}
}

@inproceedings{gaudesi2013anefficient,
  doi = {10.1145/2463372.2463495},
  url = {https://doi.org/10.1145/2463372.2463495},
  year = {2013},
  publisher = {{ACM} Press},
  author = {Marco Gaudesi and Giovanni Squillero and Alberto Tonda},
  title = {An efficient distance metric for linear genetic programming},
  booktitle = {Proceeding of the fifteenth annual conference on Genetic and evolutionary computation conference - {GECCO} {\textquotesingle}13},
  abstract = {Defining a distance measure over the individuals in the population of an Evolutionary Algorithm can be exploited for several applications, ranging from diversity preservation to balancing exploration and exploitation. When individuals are encoded as strings of bits or sets of real values, computing the distance between any two can be a straightforward process; when individuals are represented as trees or linear graphs, however, quite often the user must resort to phenotype-level problem-specific distance metrics. This paper presents a generic genotype-level distance metric for Linear Genetic Programming: the information contained by an individual is represented as a set of symbols, using n-grams to capture significant recurring structures inside the genome. The difference in information between two individuals is evaluated resorting to a symmetric difference. Experimental evaluations show that the proposed metric has a strong correlation with phenotype-level problem-specific distance measures in two problems where individuals represent string of bits and Assembly-language programs, respectively.}
}

@incollection{tonda2014balancing,
  doi = {10.1007/978-3-319-11683-9_17},
  url = {https://doi.org/10.1007/978-3-319-11683-9_17},
  year = {2014},
  publisher = {Springer International Publishing},
  pages = {211--223},
  author = {Alberto Tonda and Andre Spritzer and Evelyne Lutton},
  title = {Balancing User Interaction and Control in {BNSL}},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {In this paper we present a study based on an evolutionary framework to explore what would be a reasonable compromise between interaction and automated optimisation in finding possible solutions for a complex problem, namely the learning of Bayesian network structures, an NP-hard problem where user knowledge can be crucial to distinguish among solutions of equal fitness but very different physical meaning. Even though several classes of complex problems can be effectively tackled with Evolutionary Computation, most possess qualities that are difficult to directly encode in the fitness function or in the individual’s genotype description. Expert knowledge can sometimes be used to integrate the missing information, but new challenges arise when searching for the best way to access it: full human interaction can lead to the well-known problem of user-fatigue, while a completely automated evolutionary process can miss important contributions by the expert. For our study, we developed a GUI-based prototype application that lets an expert user guide the evolution of a network by alternating between fully-interactive and completely automatic steps. Preliminary user tests were able to show that despite still requiring some improvements with regards to its efficiency, the proposed approach indeed achieves its goal of delivering satisfying results for an expert user.}
}

@inproceedings{cani2014towards,
  doi = {10.1145/2554850.2555157},
  url = {https://doi.org/10.1145/2554850.2555157},
  year = {2014},
  publisher = {{ACM} Press},
  author = {Andrea Cani and Marco Gaudesi and Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Towards automated malware creation},
  booktitle = {Proceedings of the 29th Annual {ACM} Symposium on Applied Computing - {SAC} {\textquotesingle}14},
  abstract = {This short paper proposes two different ways for exploiting an evolutionary algorithm to devise malware: the former targeting heuristic-based anti-virus scanner; the latter optimizing a Trojan attack. An extended internal on the same the subject can be downloaded from \url{https://www.cad.polito.it/downloads/}}
}

@incollection{gaucel2014learning,
  doi = {10.1007/978-3-662-44303-3_3},
  url = {https://doi.org/10.1007/978-3-662-44303-3_3},
  year = {2014},
  publisher = {Springer Berlin Heidelberg},
  pages = {25--36},
  author = {S{\'{e}}bastien Gaucel and Maarten Keijzer and Evelyne Lutton and Alberto Tonda},
  title = {Learning Dynamical Systems Using Standard Symbolic Regression},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {Symbolic regression has many successful applications in learning free-form regular equations from data. Trying to apply the same approach to differential equations is the logical next step: so far, however, results have not matched the quality obtained with regular equations, mainly due to additional constraints and dependencies between variables that make the problem extremely hard to tackle. In this paper we propose a new approach to dynamic systems learning. Symbolic regression is used to obtain a set of first-order Eulerian approximations of differential equations, and mathematical properties of the approximation are then exploited to reconstruct the original differential equations. Advantages of this technique include the de-coupling of systems of differential equations, that can now be learned independently; the possibility of exploiting established techniques for standard symbolic regression, after trivial operations on the original dataset; and the substantial reduction of computational effort, when compared to existing ad-hoc solutions for the same purpose. Experimental results show the efficacy of the proposed approach on an instance of the Lotka-Volterra model.}
}

@inproceedings{gaudesi2014universal,
  doi = {10.1145/2598394.2598440},
  url = {https://doi.org/10.1145/2598394.2598440},
  year = {2014},
  publisher = {{ACM} Press},
  author = {Marco Gaudesi and Giovanni Squillero and Alberto Tonda},
  title = {Universal information distance for genetic programming},
  booktitle = {Proceedings of the 2014 conference companion on Genetic and evolutionary computation companion - {GECCO} Comp {\textquotesingle}14},
  abstract = {This paper presents a genotype-level distance metric for Genetic Programming (GP) based on the symmetric difference concept: first, the information contained in individuals is expressed as a set of symbols (the content of each node, its position inside the tree, and recurring parent-child structures); then, the difference between two individuals is computed considering the number of elements belonging to one, but not both, of their symbol sets.}
}

@inproceedings{bucur2014thetradeoffs,
  doi = {10.1145/2576768.2598384},
  url = {https://doi.org/10.1145/2576768.2598384},
  year = {2014},
  publisher = {{ACM} Press},
  author = {Doina Bucur and Giovanni Iacca and Giovanni Squillero and Alberto Tonda},
  title = {The tradeoffs between data delivery ratio and energy costs in wireless sensor networks},
  booktitle = {Proceedings of the 2014 conference on Genetic and evolutionary computation - {GECCO} {\textquotesingle}14},
  abstract = {Wireless sensor network (WSN) routing protocols, e.g., the Collection Tree Protocol (CTP), are designed to adapt in an ad-hoc fashion to the quality of the environment. WSNs thus have high internal dynamics and complex global behavior. Classical techniques for performance evaluation (such as testing or verification) fail to uncover the cases of extreme behavior which are most interesting to designers. We contribute a practical framework for performance evaluation of WSN protocols. The framework is based on multi-objective optimization, coupled with protocol simulation and evaluation of performance factors. For evaluation, we consider the two crucial functional and non-functional performance factors of a WSN, respectively: the ratio of data delivery from the network (DDR), and the total energy expenditure of the network (COST). We are able to discover network topological configurations over which CTP has unexpectedly low DDR and/or high COST performance, and expose full Pareto fronts which show what the possible performance tradeoffs for CTP are in terms of these two performance factors. Eventually, Pareto fronts allow us to bound the state space of the WSN, a fact which provides essential knowledge to WSN protocol designers.}
}

@inproceedings{gaudesi2014turan,
  doi = {10.1109/cec.2014.6900564},
  url = {https://doi.org/10.1109/cec.2014.6900564},
  year = {2014},
  month = jul,
  publisher = {{IEEE}},
  author = {Marco Gaudesi and Elio Piccolo and Giovanni Squillero and Alberto Tonda},
  title = {{TURAN}: Evolving non-deterministic players for the iterated prisoner{\textquotesingle}s dilemma},
  booktitle = {2014 {IEEE} Congress on Evolutionary Computation ({CEC})},
  abstract = {The iterated prisoner's dilemma is a widely known model in game theory, fundamental to many theories of cooperation and trust among self-interested beings. There are many works in literature about developing efficient strategies for this problem, both inside and outside the machine learning community. This paper shift the focus from finding a ``good strategy'' in absolute terms, to dynamically adapting and optimizing the strategy against the current opponent. Turan evolves competitive non-deterministic models of the current opponent, and exploit them to predict its moves and maximize the payoff as the game develops. Experimental results show that the proposed approach is able to obtain good performances against different kind of opponent, whether their strategies can or cannot be implemented as finite state machines.}
}

@inproceedings{descamps2015modeling,
  year = {2015},
  author = {Etienne Descamps and Alberto Tonda and S\'{e}bastien Gaucel and Ioan Cristian Trelea and Evelyne Lutton and Nathalie M\'{e}jean-Perrot},
  title = {Modeling Competition Phenomena in a Dairy Oil-in-water Emulsion Using Hybrid Kinetic Monte Carlo Simulations},
  booktitle = {Proceedings of the 6th International Symposium on Delivery of Functionality in Complex Food Systems 2015},
  abstract = {The design of models for dairy products raises a series of difficult issues. For instance, considering dairy oil in water emulsions stabilized with milk proteins, texture depends in a non-trivial manner on the initial concentration and type of proteins, nature of heat treatment and type of homogenisation. Those emulsions, involving competitive adsorption of mixed particles in a turbulent way at the oil/water interface, are not thermodynamically controlled. Classical models like the Langmuir one are thus not able to predict its behaviour with precision (Dickinson, 2011). Hybrid models (Descamps, 2014) have been recently proved to be promising for dealing with those complex phenomena. We present an extension of this approach, using an individual-­‐based framework whose implementation is based on a kinetic Monte Carlo approach (MC) combined with a mean field model. MC schemes are widely used in chemical science to deal with discrete events (Gillespie, 75). Individual-based models (also known as agent-­‐based) are convenient for representing local rules at the nano/micro scale, with macroscopic properties appearing as a consequence of an emergence process. Individual-­‐based frames, however, often rely on stochastic simulations and require time-consuming computations to yield a robust estimation for the emergent quantities. In the proposed methodology, computational efficiency is provided by performing appropriate simplifications along the simulation process thanks to an ODE-based continuous mean field formulation.}
}

@inproceedings{grosvenor2015invitro,
  year = {2015},
  author = {Anita Grosvenor and Alberto Tonda and Steven Le Feunteun and Stefan Clerens},
  title = {In Vitro and In Silico Modelling of Protein Hydrolysis by Pepsin: A Case Study with Lactoferrin},
  booktitle = {Proceedings of the 3rd International Conference on Food Structures, Digestion \& Health},
  abstract = {Unlike other digestive proteases, pepsin specificity is low. It is therefore particularly difficult to determine a priori which peptides will be released during gastric digestion, and hence in the small intestine. Detailed information about food protein truncation during digestion is however critical to understanding and optimizing the availability of bioactives, or limiting allergen release. A stochastic model that dynamically simulates the nature and quantity of peptides that are likely to be produced during pepsin hydrolysis is presented. Model predictions are compared with experimental data taken from (Grosvenor et al. 2014), which includes a list of 89 monitored peptides arising from pepsin hydrolysis of bovine lactoferrin.}
}

@incollection{bucur2015black,
  doi = {10.1007/978-3-319-16549-3_3},
  url = {https://doi.org/10.1007/978-3-319-16549-3_3},
  year = {2015},
  publisher = {Springer International Publishing},
  pages = {29--41},
  author = {Doina Bucur and Giovanni Iacca and Giovanni Squillero and Alberto Tonda},
  title = {Black Holes and Revelations: Using Evolutionary Algorithms to Uncover Vulnerabilities in Disruption-Tolerant Networks},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {A challenging aspect in open ad hoc networks is their resilience against malicious agents. This is especially true in complex, urban-scale scenarios where numerous moving agents carry mobile devices that create a peer-to-peer network without authentication. A requirement for the proper functioning of such networks is that all the peers act legitimately, forwarding the needed messages, and concurring to the maintenance of the network connectivity. However, few malicious agents may easily exploit the movement patterns in the network to dramatically reduce its performance. We propose a methodology where an evolutionary algorithm evolves the parameters of different malicious agents, determining their types and mobility patterns in order to minimize the data delivery rate and maximize the latency of communication in the network. As a case study, we consider a fine-grained simulation of a large-scale disruption-tolerant network in the city of Venice. By evolving malicious agents, we uncover situations where even a single attacker can hamper the network performance, and we correlate the performance decay to the number of malicious agents.}
}

@inproceedings{chabin2015isglobal,
  doi = {10.1145/2739482.2764675},
  url = {https://doi.org/10.1145/2739482.2764675},
  year = {2015},
  publisher = {{ACM} Press},
  author = {Thomas Chabin and Alberto Tonda and Evelyne Lutton},
  title = {Is Global Sensitivity Analysis Useful to Evolutionary Computation?},
  booktitle = {Proceedings of the Companion Publication of the 2015 on Genetic and Evolutionary Computation Conference - {GECCO} Companion {\textquotesingle}15},
  abstract = {Global Sensitivity Analysis (GSA) studies how uncertainty in the inputs of a system influences uncertainty in its outputs. GSA is extensively used by experts to gather information about the behavior of models, through computationally-intensive stochastic sampling of parameters' space. Some studies propose to make use of the considerable quantity of data acquired in this way to optimize the model parameters, often resorting to Evolutionary Algorithms (EAs). Nevertheless, efficiently exploiting information gathered from GSA might not be so straightforward. In this paper, we present a counterexample followed by experimental results to prove how naively combining GSA and EA can bring about negative outcomes.}
}

@inproceedings{belluz2015operator,
  doi = {10.1145/2739480.2754712},
  url = {https://doi.org/10.1145/2739480.2754712},
  year = {2015},
  publisher = {{ACM} Press},
  author = {Jany Belluz and Marco Gaudesi and Giovanni Squillero and Alberto Tonda},
  title = {Operator Selection using Improved Dynamic Multi-Armed Bandit},
  booktitle = {Proceedings of the 2015 on Genetic and Evolutionary Computation Conference - {GECCO} {\textquotesingle}15},
  abstract = {Evolutionary algorithms greatly benefit from an optimal application of the different genetic operators during the optimization process: thus, it is not surprising that several research lines in literature deal with the self-adapting of activation probabilities for operators. The current state of the art revolves around the use of the Multi-Armed Bandit (MAB) and Dynamic Multi-Armed bandit (D-MAB) paradigms, that modify the selection mechanism based on the rewards of the different operators. Such methodologies, however, update the probabilities after each operator's application, creating possible issues with positive feedbacks and impairing parallel evaluations, one of the strongest advantages of evolutionary computation in an industrial perspective. Moreover, D-MAB techniques often rely upon measurements of population diversity, that might not be applicable to all real-world scenarios. In this paper, we propose a generalization of the D-MAB approach, paired with a simple mechanism for operator management, that aims at removing several limitations of other D-MAB strategies, allowing for parallel evaluations and self-adaptive parameter tuning. Experimental results show that the approach is particularly effective with frameworks containing many different operators, even when some of them are ill-suited for the problem at hand, or are sporadically failing, as it commonly happens in the real world.}
}

@inproceedings{gaudesi2015malware,
  doi = {10.1145/2739482.2764940},
  url = {https://doi.org/10.1145/2739482.2764940},
  year = {2015},
  publisher = {{ACM} Press},
  author = {Marco Gaudesi and Andrea Marcelli and Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Malware Obfuscation through Evolutionary Packers},
  booktitle = {Proceedings of the Companion Publication of the 2015 on Genetic and Evolutionary Computation Conference - {GECCO} Companion {\textquotesingle}15},
  abstract = {A malicious botnet is a collection of compromised hosts coordinated by an external entity. The malicious software, or malware, that infect the systems are its basic units and they are responsible for its global behavior. Anti Virus software and Intrusion Detection Systems detect botnets by analyzing network and files, looking for signature and known behavioral patterns. Thus, the malware hiding capability is a crucial aspect. This paper describes a new obfuscation mechanism based on evolutionary algorithms: an evolutionary core is embedded in the malware to generate a different, optimized hiding strategy for every single infection. Such always-changing, hard-to-detect malware can be used by security industries to stress the analysis methodologies and to test the ability to react to malware mutations. This research is the first step in a more ambitious research project, where a whole botnet, composed of different malware and Anti Virus software, is analyzed as a prey-predator ecosystem.}
}

@inproceedings{garciasanchez2015towards,
  doi = {10.1109/cig.2015.7317940},
  url = {https://doi.org/10.1109/cig.2015.7317940},
  year = {2015},
  month = aug,
  publisher = {{IEEE}},
  author = {Pablo Garcia-Sanchez and Alberto Tonda and Antonio M. Mora and Giovanni Squillero and Juan J. Merelo},
  title = {Towards automatic {StarCraft} strategy generation using genetic programming},
  booktitle = {2015 {IEEE} Conference on Computational Intelligence and Games ({CIG})},
  abstract = {Among Real-Time Strategy games few titles have enjoyed the continued success of StarCraft. Many research lines aimed at developing Artificial Intelligences, or ``bots'', capable of challenging human players, use StarCraft as a platform. Several characteristics make this game particularly appealing for researchers, such as: asymmetric balanced factions, considerable complexity of the technology trees, large number of units with unique features, and potential for optimization both at the strategical and tactical level. In literature, various works exploit evolutionary computation to optimize particular aspects of the game, from squad formation to map exploration; but so far, no evolutionary approach has been applied to the development of a complete strategy from scratch. In this paper, we present the preliminary results of StarCraftGP, a framework able to evolve a complete strategy for StarCraft, from the building plan, to the composition of squads, up to the set of rules that define the bot's behavior during the game. The proposed approach generates strategies as C++ classes, that are then compiled and executed inside the OpprimoBot open-source framework. In a first set of runs, we demonstrate that StarCraftGP ultimately generates a competitive strategy for a Zerg bot, able to defeat several human-designed bots.}
}

@incollection{chabin2016how,
  doi = {10.1007/978-3-319-31471-6_4},
  url = {https://doi.org/10.1007/978-3-319-31471-6_4},
  year = {2016},
  publisher = {Springer International Publishing},
  pages = {44--57},
  author = {Thomas Chabin and Alberto Tonda and Evelyne Lutton},
  title = {How to Mislead an Evolutionary Algorithm Using Global Sensitivity Analysis},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {The idea of exploiting Global Sensitivity Analysis (GSA) to make Evolutionary Algorithms more effective seems very attractive: intuitively, a probabilistic analysis can prove useful to a stochastic optimisation technique. GSA, that gathers information about the behaviour of functions receiving some inputs and delivering one or several outputs, is based on computationally-intensive stochastic sampling of a parameter space. Nevertheless, efficiently exploiting information gathered from GSA might not be so straightforward. In this paper, we present three mono- and multi-objective counterexamples to prove how naively combining GSA and EA may mislead an optimisation process.}
}

@inproceedings{tonda2016foodmc,
  title = {{FoodMC: A European COST Action on Food Modelling}},
  author = {Tonda, Alberto},
  booktitle = {Proceedings of FoodSIM 2016, 9th bi-annual International Conference on Modelling and Simulation in Food Engineering},
  address = {Ghent, Belgium},
  year = {2016},
  month = apr,
  abstract = {Methodologies and tools from Maths and Computer Science (MCS) are emerging as key contributors to modernization and optimization of processes in various disciplines: the agri-food sector, however, is not a traditional domain of application for MCS, and at the moment there is no community organized around solving the issues of this field. The COST Action FoodMC brings together scientists and practitioners from MCS and agri-food domains, stimulating the emergence of new research, and structuring a new community to coordinate further investigation efforts. Exploiting approaches originating at different sub-fields of MCS, from applied mathematical models to knowledge engineering, this COST Action will cover two main topics: understanding and controlling agri-food processes; and eco-design of agri-food products.}
}

@inproceedings{boukhelifa2016research,
  TITLE = {{Research Prospects in the Design and Evaluation of Interactive Evolutionary Systems for Art and Science}},
  AUTHOR = {Boukhelifa, Nadia and Bezerianos, Anastasia and Tonda, Alberto and Lutton, Evelyne},
  BOOKTITLE = {{CHI workshop on Human Centred Machine Learning}},
  ADDRESS = {San Jose, United States},
  YEAR = {2016},
  abstract = {We report on our experience in designing and evaluating \emph{seven} applications from \emph{seven} different domains using an interactive evolutionary approach. We conducted extensive evaluations for some of these applications, both quantitative and qualitative, and collected rich feedback from our ongoing collaborations with end-user scientists and artists. To ground our discussion, we refer to two applications, from art and science, as exemplars of our work in order to identify strengths and weaknesses in our approach. We argue that human-centered design could play an important role in addressing some of the identified issues such as the ``black box'' and the ``user-bottleneck'' effects.  We discuss research opportunities requiring human-computer interaction methodologies in order to support both the visible and hidden roles that humans play in interactive evolutionary computation and  machine learning.}
}

@incollection{deplano2016portfolio,
  doi = {10.1007/978-3-319-31204-0_5},
  url = {https://doi.org/10.1007/978-3-319-31204-0_5},
  year = {2016},
  publisher = {Springer International Publishing},
  pages = {58--72},
  author = {Igor Deplano and Giovanni Squillero and Alberto Tonda},
  title = {Portfolio Optimization,  a Decision-Support Methodology for Small Budgets},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {Several machine learning paradigms have been applied to financial forecasting, attempting to predict the market’s behavior, with the final objective of profiting from trading shares. While anticipating the performance of such a complex system is far from trivial, this issue becomes even harder when the investors do not have large amounts of money available. In this paper, we present an evolutionary portfolio optimizer for the management of small budgets. The expected returns are modeled resorting to Multi-layer Perceptrons, trained on past market data, and the portfolio composition is chosen by approximating the solution to a multi-objective constrained problem. An investment simulator is then used to measure the portfolio performance. The proposed approach is tested on real-world data from Milan stock exchange, exploiting information from January 2000 to June 2010 to train the framework, and data from July 2010 to August 2011 to validate it. The presented tool is finally proven able to obtain a more than satisfying profit for the considered time frame.}
}

@incollection{gaudesi2016challenging,
  doi = {10.1007/978-3-319-31153-1_11},
  url = {https://doi.org/10.1007/978-3-319-31153-1_11},
  year = {2016},
  publisher = {Springer International Publishing},
  pages = {149--162},
  author = {Marco Gaudesi and Andrea Marcelli and Ernesto Sanchez and Giovanni Squillero and Alberto Tonda},
  title = {Challenging Anti-virus Through Evolutionary Malware Obfuscation},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {The use of anti-virus software has become something of an act of faith. A recent study showed that more than 80\% of all personal computers have anti-virus software installed. However, the protection mechanisms in place are far less effective than users would expect. Malware analysis is a classical example of cat-and-mouse game: as new anti-virus techniques are developed, malware authors respond with new ones to thwart analysis. Every day, anti-virus companies analyze thousands of malware that has been collected through honeypots, hence they restrict the research to only already existing viruses. This article describes a novel method for malware obfuscation based an evolutionary opcode generator and a special ad-hoc packer. The results can be used by the security industry to test the ability of their system to react to malware mutations.}
}

@inproceedings{lutton2016complex,
  title={Complex systems in food science: Human factor issues},
  author={Lutton, Evelyne and Tonda, Alberto and Boukhelifa, Nadia and Perrot, Nathalie},
  BOOKTITLE = {{Proceedings of FoodSIM 2016, 9th bi-annual International Conference on Modelling and Simulation in Food Engineering
}},
  ADDRESS = {Ghent, Belgium},
  YEAR = {2016},
  MONTH = Apr,
  abstract = {Building in-silico decision making systems is essential in the food domain, albeit highly difficult. This task strongly relies on multidisciplinary research and in particular on advanced techniques from artificial intelligence. The success of such systems depends on how well they cope with the complex properties of food processes, such as the large variety of interacting components including those related to human expertise; and their dynamic, non-linear, multi-scale, uncertain and non-equilibrium behaviors. Robust stochastic optimization techniques, evolutionary computation and in particular Interactive Evolutionary Computation (IEC) seem to be a fruitful framework for developing food science models. A Human-Centered approach to Interactive Evolutionary Computation is discussed in this paper as a possible pertinent way to cope with challenges related to human factors in this context.}
}

@incollection{marino2016ageneralpurpose,
  doi = {10.1007/978-3-319-45823-6_32},
  url = {https://doi.org/10.1007/978-3-319-45823-6_32},
  year = {2016},
  publisher = {Springer International Publishing},
  pages = {345--352},
  author = {Francesco Marino and Giovanni Squillero and Alberto Tonda},
  title = {A General-Purpose Framework for Genetic Improvement},
  booktitle = {Parallel Problem Solving from Nature {\textendash} {PPSN} {XIV}},
  abstract = {Genetic Improvement is an evolutionary-based technique. Despite its relatively recent introduction, several successful applications have been already reported in the scientific literature: it has been demonstrated able to modify the code complex programs without modifying their intended behavior; to increase performance with regards to speed, energy consumption or memory use. Some results suggest that it could be also used to correct bugs, restoring the software’s intended functionalities. Given the novelty of the technique, however, instances of Genetic Improvement so far rely upon ad-hoc, language-specific implementations. In this paper, we propose a general framework based on the software engineering’s idea of mutation testing coupled with Genetic Programming, that can be easily adapted to different programming languages and objective. In a preliminary evaluation, the framework efficiently optimizes the code of the md5 hash function in C, Java, and Python.}
}

@inproceedings{garciasanchez2016evolutionary,
  doi = {10.1109/cig.2016.7860426},
  url = {https://doi.org/10.1109/cig.2016.7860426},
  year = {2016},
  month = sep,
  publisher = {{IEEE}},
  author = {Pablo Garcia-Sanchez and Alberto Tonda and Giovanni Squillero and Antonio Mora and Juan J. Merelo},
  title = {Evolutionary deckbuilding in HearthStone},
  booktitle = {2016 {IEEE} Conference on Computational Intelligence and Games ({CIG})},
  abstract = {One of the most notable features of collectible card games is deckbuilding, that is, defining a personalized deck before the real game. Deckbuilding is a challenge that involves a big and rugged search space, with different and unpredictable behaviour after simple card changes and even hidden information. In this paper, we explore the possibility of automated deckbuilding: a genetic algorithm is applied to the task, with the evaluation delegated to a game simulator that tests every potential deck against a varied and representative range of human-made decks. In these preliminary experiments, the approach has proven able to create quite effective decks, a promising result that proves that, even in this challenging environment, evolutionary algorithms can find good solutions.}
}

@inproceedings{grosvenor2017pepsin,
  year = {2017},
  author = {Alberto Tonda and Anita Grosvenor and Stefan Clerens and Steven Le Feunteun},
  title = {In-silico Predictions of Pepsin-released Peptides},
  booktitle = {Proceedings of the International conference on Food Digestion 2017},
  abstract = {Pepsin is the first protease encountered within the digestive tract. Unlike other digestive proteases, its specificity is low. It is therefore particularly difficult to determine a priori which peptides will be released during gastric digestion. Detailed information about food protein truncation during digestion is however critical to understanding and optimizing the availability of bioactives, or limiting allergen release. In this study, a stochastic model which tries to reproduce the dynamics of protein hydrolysis by pepsin is presented. The model is based on pepsin cleavage frequency tables taken from the literature, and makes use of Monte-Carlo in silico simulations to quantitatively predict peptides that are likely to be produced by pepsin during the course of the reaction. The proposed model, which requires the expected hydrolysis kinetics and the amino-acid sequence of the studied protein to run, was applied to bovine lactoferrin. Model predictions were then compared with 89 peptides experimentally observed with a peptidomic approach using isobaric labelling during 2h gastric digestion experiments (Grosvenor et al., Food and Function, 2014). The model was found to reproduce many real-world features of the case study, such as the relative peptide abundance summary maps along the protein sequence (peptide patterns) or peptide size distribution. It even appeared that 50\% of experimentally observed peptides (45/89) fall within the 164 most abundant predicted peptides (over a total of \~ 1500 predicted peptides). These first results illustrate that in silico modelling of pepsin hydrolysis is a promising approach to determine which peptides are likely to be released during gastric digestion of foods.}
}

@incollection{bucur2017multiobjective,
  doi = {10.1007/978-3-319-55849-3_15},
  url = {https://doi.org/10.1007/978-3-319-55849-3_15},
  year = {2017},
  publisher = {Springer International Publishing},
  pages = {221--233},
  author = {Doina Bucur and Giovanni Iacca and Andrea Marcelli and Giovanni Squillero and Alberto Tonda},
  title = {Multi-objective Evolutionary Algorithms for Influence Maximization in Social Networks},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {As the pervasiveness of social networks increases, new NPhard related problems become interesting for the optimization community. The objective of influence maximization is to contact the largest
possible number of nodes in a network, starting from a small set of seed
nodes, and assuming a model for information propagation. This problem
is of utmost practical importance for applications ranging from social
studies to marketing. The influence maximization problem is typically
formulated assuming that the number of the seed nodes is a parameter.
Differently, in this paper, we choose to formulate it in a multi-objective
fashion, considering the minimization of the number of seed nodes among
the goals, and we tackle it with an evolutionary approach. As a result,
we are able to identify sets of seed nodes of different size that spread
influence the best, providing factual data to trade-off costs with quality
of the result. The methodology is tested on two real-world case studies,
using two different influence propagation models, and compared against
state-of-the-art heuristic algorithms. The results show that the proposed
approach is almost always able to outperform the heuristics.}
}

@inproceedings{chabin2017interactive,
  doi = {10.1145/3067695.3075992},
  url = {https://doi.org/10.1145/3067695.3075992},
  year = {2017},
  month = jul,
  publisher = {{ACM}},
  author = {Thomas Chabin and Marc Barnab{\'{e}} and Nadia Boukhelifa and Fernanda Fonseca and Alberto Tonda and H{\'{e}}l{\`{e}}ne Velly and Nathalie M\'{e}jean-Perrot and Evelyne Lutton},
  title = {Interactive evolutionary modelling of living complex food systems},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  abstract = {Modelling the production and stabilisation process of lactic acid starters has several practical applications, ranging from assessing the efficacy of new industrial methods, to proposing alternative sustainable systems of food production. In order to reach this objective, however, it is necessary to overcome several obstacles, tied to the complex nature and interactions of the target processes. In this paper, we present a novel complex system modelling approach, exploiting both stand-alone evolutionary search and visual interaction with the user. The presented framework is then tested on a real-world case study, for which it shows promising results.}
}

@inproceedings{tonda2017foodmc,
  year = {2017},
  author = {Alberto Tonda},
  title = {FoodMC: a COST Action to Promote Modeling in Food Science and Industry},
  booktitle = {Proceedings of the IOBC conference on Integrated Protection of Stored Products},
  abstract = {Methodologies and tools from Maths and Computer Science (MCS) are emerging as key contributors to modernization and optimization of processes in various disciplines: the agri-food sector, however, is not a traditional domain of application for MCS, and at the moment there is no community organized around solving the issues of this field. The COST Action FoodMC brings together scientists and practitioners from MCS and agri-food domains, stimulating the emergence of new research, and structuring a new community to coordinate further investigation efforts. Exploiting approaches originating at different subfields of MCS, from applied mathematical models to knowledge engineering, this COST Action will cover two main topics: understanding and controlling agri-food processes; and eco-design of agri-food products. During its first year of existence, COST Action FoodMC helped fund several international collaborations between European researchers, fostered the drafting of survey papers on food modelling, organized meetings for discussion, and co-funded a training school.}
}

@incollection{chabin2018lideogram,
  doi = {10.1007/978-3-319-78133-4_14},
  url = {https://doi.org/10.1007/978-3-319-78133-4_14},
  year = {2018},
  publisher = {Springer International Publishing},
  pages = {189--201},
  author = {Thomas Chabin and Marc Barnab{\'{e}} and Nadia Boukhelifa and Fernanda Fonseca and Alberto Tonda and H{\'{e}}l{\`{e}}ne Velly and Benjamin Lemaitre and Nathalie Perrot and Evelyne Lutton},
  title = {{LIDeOGraM}: An Interactive Evolutionary Modelling Tool},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {Building complex models from available data is a challenge in many domains, and in particular in food science. Numerical data are often not enough structured, or simply not enough to elucidate complex structures : human choices have thus a major impact at various levels (data and model structuration, choice of representative scales, parameter ranges, uncertainty assessment and management, expert knowledge). LIDeOGraM is an interactive modelling framework adapted to cases where numerical data and expert knowledge have to be combined for building an ecient model. Exploiting both stand-alone evolutionary search and visual interaction with the user, the proposed methodology aims at obtaining an accurate global model for the system, balancing expert knowledge with information automatically extracted from available data. The presented framework is tested on a real-world case study from food science : the production and stabilisation of lactic acid bacteria, which has several important practical applications, ranging from assessing the ecacy of new industrial methods, to proposing alternative sustainable systems of food production.}
}

@incollection{bucur2018improving,
  doi = {10.1007/978-3-319-77538-8_9},
  url = {https://doi.org/10.1007/978-3-319-77538-8_9},
  year = {2018},
  publisher = {Springer International Publishing},
  pages = {117--124},
  author = {Doina Bucur and Giovanni Iacca and Andrea Marcelli and Giovanni Squillero and Alberto Tonda},
  title = {Improving Multi-objective Evolutionary Influence Maximization in Social Networks},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {In the context of social networks, maximizing influence means contacting the largest possible number of nodes starting from a set of seed nodes, and assuming a model for influence propagation. The real-world applications of influence maximization are of uttermost importance, and range from social studies to marketing campaigns. Building on a previous work on multi-objective evolutionary influence maximization, we propose improvements that not only speed up the optimization process considerably, but also deliver higher-quality results. State-of-the-art heuristics are run for different sizes of the seed sets, and the results are then used to initialize the population of a multi-objective evolutionary algorithm. The proposed approach is tested on three publicly available real-world networks, where we show that the evolutionary algorithm is able to improve upon the solutions found by the heuristics, while also converging faster than an evolutionary algorithm started from scratch.}
}

@inproceedings{tonda2018alongshorttermmemory,
  year = {2018},
  author = {Tonda, Alberto and M\'{e}jean-Perrot, Nathalie},
  title = {A Long-Short-Term Memory Network Model for Biscuit Baking},
  booktitle = {Proceedings of FoodSIM 2018, 10th bi-annual International Conference on Modelling and Simulation in Food Engineering},
  isbn = {978-9492859-01-3},
  abstract = {Long-Short-Term Memory (LSTM) networks are a relatively recent addition to the field of Artificial Neural Networks (ANNs). LSTM networks are specifically tailored for machine learning of time series, where the outputs of a system are not just a function of their inputs, but also of a internal state. The state itself can be seen as dependent on the historical series of all inputs seen by the system up to that point in time. In this paper, we present an application of LSTM networks to the modeling of biscuit baking. Starting from 16 real-world time series of biscuit baking, gathered by the United Biscuits company under different conditions, we show how the proposed LSTM network can correctly predict unseen values. Remarkably, the network is also able to reproduce a dynamic behavior up to variations that might be overlooked as noise.}
}

@inproceedings{mejean2018human,
  year = {2018},
  author = {M\'{e}jean-Perrot, Nathalie and Boukhelifa, Nadia and Tonda, Alberto and Chabin, Thomas and Barnab\'{e}, Marc and Swennen, Dominique and Roche, Alice and Thomas-Danguin, Thomas and Lutton, Evelyne},
  title = {Human in the Loop for Modelling Food and Biological Systems: a Novel Perspective coupling Artificial Intelligence and Life Science},
  booktitle = {Proceedings of FoodSIM 2018, 10th bi-annual International Conference on Modelling and Simulation in Food Engineering},
  isbn = {978-9492859-01-3},
  abstract = {Since centuries, agriculture, food and biological systems are strongly linked to human expertise, albeit such knowledge has been capitalized and shared often at a local level, only. Since the beginning of the last century, swept away by productivism, modern agriculture and food production have put cumulated human knowledge aside. Facing new challenges like sustainability in a changing context, holistic approaches cannot be managed ``manually'' ab initio and there is a clear need for computing decision-support tools to tackle these new issues. Moreover, new approaches should be built centred on humans and for humans. The heart of our purpose is to shift the focus again on human and local expertise, guided by powerful computing interactive systems.}
}

@inproceedings{chabin2018asemiautomatic,
  year = {2018},
  author = {Chabin, Thomas and Barnab\'{e}, Marc and Tonda, Alberto and Boukhelifa, Nadia and Fonseca, Fernanda and Dugat-Bony, Eric and Velly, H{\'{e}}l{\`{e}}ne and Lutton, Evelyne and M\'{e}jean-Perrot, Nathalie},
  title = {A Semi-automatic Modeling Approach for the Production and Freeze-drying of Lactic Acid Bacteria},
  booktitle = {Proceedings of FoodSIM 2018, 10th bi-annual International Conference on Modelling and Simulation in Food Engineering},
  isbn = {978-9492859-01-3},
  abstract = {The production system of freeze-dried lactic acid bacteria involves several processes, but its impact on bacteria resistance is still not well understood. This system can be defined as a complex one since it depends on multiple scales: the Genomic, the Cellular and the Population scale. The scarcity of data available for building models leads us to propose an approach that makes use of expert knowledge. In this paper we present a semiautomatic modelling tool, LIDEOGRAM and discuss how it contributes to insight formulation and rapid hypothesis testing. New results show that LIDEOGRAM is able to produce more robust modelling hypotheses when experts can interact and revisit the genomic data preprocessing.}
}

@inproceedings{bucur2018evaluating,
  doi = {10.1145/3205651.3208238},
  url = {https://doi.org/10.1145/3205651.3208238},
  year = {2018},
  month = jul,
  publisher = {{ACM}},
  author = {Doina Bucur and Giovanni Iacca and Andrea Marcelli and Giovanni Squillero and Alberto Tonda},
  title = {Evaluating surrogate models for multi-objective influence maximization in social networks},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  abstract = {One of the most relevant problems in social networks is influence maximization, that is the problem of finding the set of the most influential nodes in a network, for a given influence propagation model. As the problem is NP-hard, recent works have attempted to solve it by means of computational intelligence approaches, for instance Evolutionary Algorithms. However, most of these methods are of limited applicability for real-world large-scale networks, for two reasons: on the one hand, they require a large number of candidate solution evaluations to converge; on the other hand, each evaluation is computationally expensive in that it needs a considerable number of Monte Carlo simulations to obtain reliable values. In this work, we consider a possible solution to such limitations, by evaluating a surrogate-assisted Multi-Objective Evolutionary Algorithm that uses an approximate model of influence propagation (instead of Monte Carlo simulations) to find the minimum-sized set of most influential nodes. Experiments carried out on two social networks datasets suggest that approximate models should be carefully considered before using them in influence maximization approaches, as the errors induced by these models are in some cases too big to benefit the algorithmic performance.}
}

@inproceedings{tonda2018building,
  year = {2018},
  author = {Alberto Tonda},
  title = {Building a Multidisciplinary Community on Mathematics and Computer Science for the Food Industry: The Case of FoodMC},
  booktitle = {Book of Abstracts of the 5th International {ISEKI}\_{F}ood Conference},
  isbn = {978-3-900932-57-2},
  abstract = {Presentation of COST Action CA15118 FoodMC.}
}

@incollection{barbiero2019understanding,
  doi = {10.1007/978-981-13-8950-4_26},
  url = {https://doi.org/10.1007/978-981-13-8950-4_26},
  year = {2019},
  month = sep,
  publisher = {Springer Singapore},
  pages = {281--290},
  author = {Pietro Barbiero and Andrea Bertotti and Gabriele Ciravegna and Giansalvo Cirrincione and Elio Piccolo and Alberto Tonda},
  title = {Understanding Cancer Phenomenon at Gene Expression Level by using a Shallow Neural Network Chain},
  booktitle = {Neural Approaches to Dynamics of Signal Exchanges},
  abstract = {Exploiting the availability of the largest collection of patient-derived xenografts from metastatic colorectal cancer annotated for a response to therapies, this manuscript aims to characterize the biological phenomenon from a mathematical point of view. In particular, we design an experiment in order to investigate how genes interact with each other. By using a shallow neural network model, we find reduced feature subspaces where the resistance phenomenon may be much easier to understand and analyze.}
}

@incollection{barbiero2019fundamental,
  doi = {10.1007/978-3-030-16692-2_37},
  url = {https://doi.org/10.1007/978-3-030-16692-2_37},
  year = {2019},
  publisher = {Springer International Publishing},
  pages = {550--564},
  author = {Pietro Barbiero and Alberto Tonda},
  title = {Fundamental Flowers: Evolutionary Discovery of Coresets for Classification},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {In an optimization problem, a coreset can be defined as a subset of the input points, such that a good approximation to the optimization problem can be obtained by solving it directly on the coreset, instead of using the whole original input. In machine learning, coresets are exploited for applications ranging from speeding up training time, to helping humans understand the fundamental properties of a class, by considering only a few meaningful samples. The problem of discovering coresets, starting from a dataset and an application, can be defined as identifying the minimal amount of samples that do not significantly lower performance with respect to the performance on the whole dataset. Specialized literature offers several approaches to finding coresets, but such algorithms often disregard the application, or explicitly ask the user for the desired number of points. Starting from the consideration that finding coresets is an intuitively multi-objective problem, as minimizing the number of points goes against maintaining the original performance, in this paper we propose a multi-objective evolutionary approach to identifying coresets for classification. The proposed approach is tested on classical machine learning classification benchmarks, using 6 state-of-the-art classifiers, comparing against 7 algorithms for coreset discovery. Results show that not only the proposed approach is able to find coresets representing different compromises between compactness and performance, but that different coresets are identified for different classifiers, reinforcing the assumption that coresets might be closely linked to the specific application.}
}

@incollection{barbiero2020generating,
  doi = {10.1007/978-3-030-38227-8_6},
  url = {https://doi.org/10.1007/978-3-030-38227-8_6},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {45--52},
  author = {Pietro Barbiero and Gabriele Ciravegna and Giansalvo Cirrincione and Alberto Tonda and Giovanni Squillero},
  title = {Generating Neural Archetypes to Instruct Fast and Interpretable Decisions},
  booktitle = {Advances in Intelligent Systems and Computing},
  abstract = {In the field of artificial intelligence, agents learn how to take decisions by fitting their parameters on a set of samples called training set. Similarly, a core set is a subset of the training samples such that, if an agent exploits this set to fit its parameters instead of the whole training set, then the quality of the inferences does not change significantly. Relaxing the constraint that restricts the search for core sets to the available data, neural networks may be used to generate virtual samples, called archetype set, containing the same kind of information. This work illustrates the features of GH-ARCH, a recently proposed self-organizing hierarchical neural network for archetype discovery. Experiments show how the use of archetypes allows both ML agents to make fast and accurate predictions and human experts to make sense of such decisions by analyzing few important samples.}
}

@incollection{barbiero2020making,
  doi = {10.1007/978-3-030-38227-8_19},
  url = {https://doi.org/10.1007/978-3-030-38227-8_19},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {162--170},
  author = {Pietro Barbiero and Alberto Tonda},
  title = {Making Sense of Economics Datasets with Evolutionary Coresets},
  booktitle = {Advances in Intelligent Systems and Computing},
  abstract = {Machine learning agents learn to take decisions extracting information from training data. When similar inferences can be obtained using a small subset of the same training set of samples, the subset is called coreset. Coresets discovery is an active line of research as it may be used to reduce the training speed as well as to allow human experts to gain a better understanding of both the phenomenon and the decisions, by reducing the number of samples to be examined. For classification problems, the state-of-the-art in coreset discovery is EvoCore, a multi-objective evolutionary algorithm. In this work EvoCore is exploited both on synthetic and on real data sets, showing how coresets may be useful in explaining decisions taken by machine learning classifiers.}
}

@inproceedings{barbiero2019beyond,
  doi = {10.1145/3319619.3326789},
  url = {https://doi.org/10.1145/3319619.3326789},
  year = {2019},
  month = jul,
  publisher = {{ACM}},
  author = {Pietro Barbiero and Giovanni Squillero and Alberto Tonda},
  title = {Beyond coreset discovery},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  abstract = {In machine learning a coreset is defined as a subset of the training set using which an algorithm obtains performances similar to what it would deliver if trained over the whole original data. Advantages of coresets include improving training speed and easing human understanding. Coreset discovery is an open line of research as limiting the training might also impair the quality of the result. Differently, virtual points, here called archetypes, might be far more informative for a machine learning algorithm. Starting from this intuition, a novel evolutionary approach to archetype set discovery is presented: starting from a population seeded with candidate coresets, a multi-objective evolutionary algorithm is set to modify them and eventually create archetype sets, to minimize both number of points in the set and classification error. Experimental results on popular benchmarks show that the proposed approach is able to deliver results that allow a classifier to obtain lower error and better ability of generalizing on unseen data than state-of-the-art coreset discovery techniques.}
}

@inproceedings{barbiero2019evolutionary,
  doi = {10.1145/3319619.3326846},
  url = {https://doi.org/10.1145/3319619.3326846},
  year = {2019},
  month = jul,
  publisher = {{ACM}},
  author = {Pietro Barbiero and Giovanni Squillero and Alberto Tonda},
  title = {Evolutionary discovery of coresets for classification},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
  abstract = {When a machine learning algorithm is able to obtain the same performance given a complete training set, and a small subset of samples from the same training set, the subset is termed coreset. As using a coreset improves training speed and allows human experts to gain a better understanding of the data, by reducing the number of samples to be examined, coreset discovery is an active line of research. Often in literature the problem of coreset discovery is framed as i. single-objective, attempting to find the candidate coreset that best represents the training set, and ii. independent from the machine learning algorithm used. In this work, an approach to evolutionary coreset discovery is presented. Building on preliminary results, the proposed approach uses a multi-objective evolutionary algorithm to find compromises between two conflicting objectives, i. minimizing the number of samples in a candidate coreset, and ii. maximizing the accuracy of a target classifier, trained with the coreset, on the whole original training set. Experimental results on popular classification benchmarks show that the proposed approach is able to identify candidate coresets with better accuracy and generality than state-of-the-art coreset discovery algorithms found in literature.}
}

@incollection{ciravegna2020discovering,
  doi = {10.1007/978-981-15-5093-5_24},
  url = {https://doi.org/10.1007/978-981-15-5093-5_24},
  year = {2020},
  month = jul,
  publisher = {Springer Singapore},
  pages = {255--267},
  author = {Gabriele Ciravegna and Pietro Barbiero and Giansalvo Cirrincione and Giovanni Squillero and Alberto Tonda},
  title = {Discovering Hierarchical Neural Archetype Sets},
  booktitle = {Progresses in Artificial Intelligence and Neural Systems},
  abstract = {In the field of machine learning, coresets are defined as subsets of the training set that can be used to obtain a good approximation of the behavior that a given algorithm would have on the whole training set. Advantages of using coresets instead of the training set include improving training speed and allowing for a better human understanding of the dataset. Not surprisingly, coreset discovery is an active research line, with several notable contributions in literature. Nevertheless, restricting the search for representative samples to the available data points might impair the final result. In this work, neural networks are used to create sets of virtual data points, named archetypes, with the objective to represent the information contained in a training set, in the same way a coreset does. Starting from a given training set, a hierarchical clustering neural network is trained and the weight vectors of the leaves are used as archetypes on which the classifiers are trained. Experimental results on several benchmarks show that the proposed approach is competitive with traditional coreset discovery techniques, delivering results with higher accuracy, and showing a greater ability to generalize to unseen test data.}
}

@incollection{giovannitti2020virtual,
  doi = {10.1007/978-3-030-37838-7_17},
  url = {https://doi.org/10.1007/978-3-030-37838-7_17},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {189--200},
  author = {Eliana Giovannitti and Giovanni Squillero and Alberto Tonda},
  title = {Virtual Measurement of the Backlash Gap in Industrial Manipulators},
  booktitle = {Communications in Computer and Information Science},
  abstract = {Industrial manipulators are robots used to replace humans in dangerous or repetitive tasks. Also, these devices are often used for applications where high precision and accuracy is required. The increase of backlash caused by wear, that is, the increase of the amount by which teeth space exceeds the thickness of gear teeth, might be a significant problem, that could lead to impaired performances or even abrupt failures. However, maintenance is difficult to schedule because backlash cannot be directly measured and its effects only appear in closed loops. This paper proposes a novel technique, based on an Evolutionary Algorithm, to estimate the increase of backlash in a robot joint transmission. The peculiarity of this method is that it only requires measurements from the motor encoder. Experimental evaluation on a real-world test case demonstrates the effectiveness of the approach.}
}

@incollection{barbiero2020anovel,
  doi = {10.1007/978-3-030-45715-0_6},
  url = {https://doi.org/10.1007/978-3-030-45715-0_6},
  year = {2020},
  publisher = {Springer International Publishing},
  pages = {68--81},
  author = {Pietro Barbiero and Evelyne Lutton and Giovanni Squillero and Alberto Tonda},
  title = {A Novel Outlook on Feature Selection as a Multi-objective Problem},
  booktitle = {Lecture Notes in Computer Science},
  abstract = {Feature selection is the process of choosing, or removing, features to obtain the most informative feature subset of minimal size. Such subsets are used to improve performance of machine learning algorithms and enable human understanding of the results. Approaches to feature selection in literature exploit several optimization algorithms. Multi-objective methods also have been proposed, minimizing at the same time the number of features and the error. While most approaches assess error resorting to the average of a stochastic K-fold cross-validation, comparing averages might be misleading. In this paper, we show how feature subsets with different average error might in fact be non-separable when compared using a statistical test. Following this idea, clusters of non-separable optimal feature subsets are identified. The performance in feature selection can thus be evaluated by verifying how many of these optimal feature subsets an algorithm is able to identify. We thus propose a multi-objective optimization approach to feature selection, EvoFS, with the objectives to i. minimize feature subset size, ii. minimize test error on a 10-fold cross-validation using a specific classifier, iii. maximize the analysis of variance value of the lowest-performing feature in the set. Experiments on classification datasets whose feature subsets can be exhaustively evaluated show that our approach is able to always find the best feature subsets. Further experiments on a high-dimensional classification dataset, that cannot be exhaustively analyzed, show that our approach is able to find more optimal feature subsets than state-of-the-art feature selection algorithms.}
}

@inproceedings{djekic2020environmental,
  year = {2020},
  author = {Ilija Djekic and Jan Van Impe and Alberto Tonda},
  title = {Environmental Modelling in the Food Supply Chain - Future Perspectives},
  booktitle = {Proceedings of FoodSIM 2020, 11th bi-annual International Conference on Modelling and Simulation in Food Engineering},
  abstract = {Interaction of food systems and the environment has been in research focus for many years. In order to explain this interaction, scholars have developed and use various approaches in modelling and understanding this phenomenon. This paper gives an overview of three main perspectives in analyzing this issue and provides some future perspectives associated with sustainable development goals developed by the UN.}
}

@inproceedings{lopezrincon2020batch,
  doi = {10.1145/3377929.3389947},
  url = {https://doi.org/10.1145/3377929.3389947},
  year = {2020},
  month = jul,
  publisher = {{ACM}},
  author = {Alejandro Lopez Rincon and Aletta D. Kraneveld and Alberto Tonda},
  title = {Batch correction of genomic data in chronic fatigue syndrome using {CMA}-{ES}},
  booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
  abstract = {Modern genomic sequencing machines can measure thousands of probes from different specimens. Nevertheless, theoretically comparable datasets can show considerably distinguishable properties, depending on both platform and specimen, a phenomenon known as batch effect. Batch correction is the technique aiming at removing this effect from the data. A possible approach to batch correction is to find a transformation function between different datasets, but optimizing the weights of such a function is not trivial: As there is no explicit gradient to follow, traditional optimization techniques would fail. In this work, we propose to use a state-of-the-art evolutionary algorithm, Covariance Matrix Adaptation Evolution Strategy, to optimize the weights of a transformation function for batch correction. The fitness function is driven by the classification accuracy of an ensemble of algorithms on the transformed data. The case study selected to test the proposed approach is mRNA gene expression data of Chronic Fatigue Syndrome, a disease for which there is currently no established diagnostic test. The transformation function obtained from three datasets, produced from different specimens, remarkably improves the performance of classifiers on the task of diagnosing Chronic Fatigue. The presented results are an important steppingstone towards a reliable diagnostic test for this syndrome.}
}

@inproceedings{squillero2020evolutionary,
  doi = {10.1145/3377929.3389863},
  url = {https://doi.org/10.1145/3377929.3389863},
  year = {2020},
  month = jul,
  publisher = {{ACM}},
  author = {Giovanni Squillero and Alberto Tonda},
  title = {Evolutionary algorithms and machine learning},
  booktitle = {Proceedings of the 2020 Genetic and Evolutionary Computation Conference Companion},
  abstract = {Tutorial on evolutionary algorithms and machine learning. Slides are available from the DOI link.}
}

@incollection{doerr2016tutorials,
  doi = {10.1007/978-3-319-45823-6_95},
  url = {https://doi.org/10.1007/978-3-319-45823-6_95},
  year = {2016},
  publisher = {Springer International Publishing},
  pages = {1012--1022},
  author = {Carola Doerr and Nicolas Bredeche and Enrique Alba and Thomas Bartz-Beielstein and Dimo Brockhoff and Benjamin Doerr and Gusz Eiben and Michael G. Epitropakis and Carlos M. Fonseca and Andreia Guerreiro and Evert Haasdijk and Jacqueline Heinerman and Julien Hubert and Per Kristian Lehre and Luigi Malag{\`{o}} and J. J. Merelo and Julian Miller and Boris Naujoks and Pietro Oliveto and Stjepan Picek and Nelishia Pillay and Mike Preuss and Patricia Ryser-Welch and Giovanni Squillero and J\"{o}rg Stork and Dirk Sudholt and Alberto Tonda and Darrell Whitley and Martin Zaefferer},
  title = {Tutorials at {PPSN} 2016},
  booktitle = {Parallel Problem Solving from Nature {\textendash} {PPSN} {XIV}},
  abstract = {PPSN 2016 hosts a total number of 16 tutorials covering a broad range of current research in evolutionary computation. The tutorials range from introductory to advanced and specialized but can all be attended without prior requirements. All PPSN attendees are cordially invited to take this opportunity to learn about ongoing research activities in our field!}
}

@incollection{merelo2016theuncertainty,
  doi = {10.1007/978-3-662-53525-7_3},
  url = {https://doi.org/10.1007/978-3-662-53525-7_3},
  year = {2016},
  publisher = {Springer Berlin Heidelberg},
  pages = {40--60},
  author = {Juan J. Merelo and Federico Liberatore and Antonio Fern{\'{a}}ndez Ares and Rub{\'{e}}n Garc{\'{\i}}a and Zeineb Chelly and Carlos Cotta and Nuria Rico and Antonio M. Mora and Pablo Garc{\'{\i}}a-S{\'{a}}nchez and Alberto Tonda and Paloma de las Cuevas and Pedro A. Castillo},
  title = {The Uncertainty Quandary: A Study in the Context of the Evolutionary Optimization in Games and Other Uncertain Environments},
  booktitle = {Transactions on Computational Collective Intelligence {XXIV}},
  abstract = {In many optimization processes, the fitness or the considered measure of goodness for the candidate solutions presents uncertainty, that is, it yields different values when repeatedly measured, due to the nature of the evaluation process or the solution itself. This happens quite often in the context of computational intelligence in games, when either bots behave stochastically, or the target game possesses intrinsic random elements, but it shows up also in other problems as long as there is some random component. Thus, it is important to examine the statistical behavior of repeated measurements of performance and, more specifically, the statistical distribution that better fits them. This work analyzes four different problems related to computational intelligence in videogames, where Evolutionary Computation methods have been applied, and the evaluation of each individual is performed by playing the game, and compare them to other problem, neural network optimization, where performance is also a statistical variable. In order to find possible patterns in the statistical behavior of the variables, we track the main features of its distributions, skewness and kurtosis. Contrary to the usual assumption in this kind of problems, we prove that, in general, the values of two features imply that fitness values do not follow a normal distribution; they do present a certain common behavior that changes as evolution proceeds, getting in some cases closer to the standard distribution and in others drifting apart from it. A clear behavior in this case cannot be concluded, other than the fact that the statistical distribution that fitness variables follow is affected by selection in different directions, that parameters vary in a single generation across them, and that, in general, this kind of behavior will have to be taken into account to adequately address uncertainty in fitness in evolutionary algorithms.}
}

@incollection{lopezrincon2021modelling,
  doi = {10.1007/978-3-030-72699-7_23},
  url = {https://doi.org/10.1007/978-3-030-72699-7_23},
  year = {2021},
  publisher = {Springer International Publishing},
  pages = {359--372},
  author = {Alejandro Lopez-Rincon and Daphne S. Roozendaal and Hilde M. Spierenburg and Asta L. Holm and Renee Metcalf and Paula Perez-Pardo and Aletta D. Kraneveld and Alberto Tonda},
  title = {Modelling Asthma Patients' Responsiveness to Treatment Using Feature Selection and Evolutionary Computation},
  booktitle = {Applications of Evolutionary Computation},
  abstract = {For several medical treatments, it is possible to observe transcriptional variations in gene expressions between responders and non-responders. Modelling the correlation between such variations and the patient’s response to drugs as a system of Ordinary Differential Equations could be invaluable to improve the efficacy of treatments and would represent an important step towards personalized medicine. Two main obstacles lie on this path: (i) the number of genes is too large to straightforwardly analyze their interactions; (ii) defining the correct parameters for the mathematical models of gene interaction is a complex optimization problem, even when a limited number of genes is involved. In this paper, we propose a novel approach to creating mathematical models able to explain patients’ response to treatment from transcriptional variations. The approach is based on: (i) a feature selection algorithm, set to identify a minimal set of gene expressions that are highly correlated with treatment outcome, (ii) a state-of-the-art evolutionary optimizer, Covariance Matrix Adaptation Evolution Strategy, applied to finding the parameters of the mathematical model characterizing the relationship between gene expressions and patient responsiveness. The proposed methodology is tested on real-world data describing responsiveness of asthma patients to Omalizumab, a humanized monoclonal antibody that binds to immunoglobulin E. In this case study, the presented approach is shown able to identify 5 genes (out of 28,402) that are transcriptionally relevant to predict treatment outcomes, and to deliver a compact mathematical model that is able to explain the interaction between the different genes involved.}
}

@inproceedings{giovannitti2021exploiting,
  doi = {10.1109/cec45853.2021.9504962},
  url = {https://doi.org/10.1109/cec45853.2021.9504962},
  year = {2021},
  month = jun,
  publisher = {{IEEE}},
  author = {Eliana Giovannitti and Sayyidshahab Nabavi and Giovanni Squillero and Alberto Tonda},
  title = {Exploiting Artificial Swarms for the Virtual Measurement of Backlash in Industrial Robots},
  booktitle = {2021 {IEEE} Congress on Evolutionary Computation ({CEC})},
  abstract = {The backlash is a lost motion in a mechanism created by gaps between its parts. It causes vibrations that increase over time and negatively affect accuracy and performance. The quickest and most precise way to measure the backlash is to use specific sensors, that have to be added to the standard equipment of the robot. However, this solution is little used in practice because raises the manufacturing costs. An alternative solution can be to exploit a virtual sensor, i.e., the information about phenomena that are not directly measured is reconstructed by signals from sensors used for other measurements.This work evaluates the use of bio-inspired swarm algorithms as the processing core of a virtual sensor for the backlash of a robotic joint. Swarm-based approaches, with their relatively modest occupation of memory and low computational load, could be ideal candidates to solve the problem. In this paper, we exploit four state-of-the-art swarm-based optimization algorithms: the Dragonfly Algorithm, the Ant Lion Optimizer, the Grasshopper Optimization Algorithm, and the Grey Wolf Optimizer. The four candidate algorithms are compared on 20 different datasets covering a range of backlash values that reflect an industrial case scenario. Numerical results indicate that, unfortunately, none of the algorithms considered provides satisfactory solutions for the problem analyzed. Therefore, even if promising, these algorithms cannot represent the final choice for the problem of interest.}
}

@inproceedings{lopezrincon2021design,
  doi = {10.1145/3449639.3459359},
  url = {https://doi.org/10.1145/3449639.3459359},
  year = {2021},
  month = jun,
  publisher = {{ACM}},
  author = {Alejandro Lopez Rincon and Carmina A. Perez Romero and Lucero Mendoza Maldonado and Eric Claassen and Johan Garssen and Aletta D. Kraneveld and Alberto Tonda},
  title = {Design of specific primer sets for {SARS}-{CoV}-2 variants using evolutionary algorithms},
  booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
  abstract = {Primer sets are short DNA sequences of 18-22 base pairs, that can be used to verify the presence of a virus, and designed to attach to a specific part of a viral DNA. Designing a primer set requires choosing a region of DNA, avoiding the possibility of hybridization to a similar sequence, as well as considering its GC content and $T_m$ (melting temperature). Coronaviruses, such as SARS-CoV-2, have a considerably large genome (around 30 thousand nucleotides) when compared to other viruses. With the rapid rise and spread of SARS-CoV-2 variants, it has become a priority to breach our lack of specific primers available for diagnosis of this new variants. Here, we propose an evolutionary-based approach to primer design, able to rapidly deliver a high-quality primer set for a target sequence of the virus variant. Starting from viral sequences collected from open repositories, the proposed approach is proven able to uncover a specific primer set for the B.1.1.7 SARS-CoV-2 variant. Only recently identified, B.1.1.7 is already considered potentially dangerous, as it presents a considerably higher transmissibility when compared to other variants.}
}


@inproceedings{mouhrim2022towards,
author = {Mouhrim, Nisrine and Smetana, Sergiy and Bhatia, Anita and Mathys, Alexander and Green, Ashley and Peguero, Daniela and Tonda, Alberto},
title = {Towards Multi-Objective Optimization of Sustainable Insect Production Chains},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3528898},
doi = {10.1145/3520304.3528898},
abstract = {Due to the relatively recent history of industrial insect farming, there are still no extensive studies on the optimization of insect production chains. In this context, the present work aims to be a first step in filling this gap. A tentative set of mathematical models is proposed to take into account three different, conflicting objectives: maximizing economic viability, minimizing environmental impacts, and maximizing societal benefits. The state-of-the-art multi-objective algorithm NSGA-II is used to obtain an approximate Pareto fronts of solutions, that are later analyzed to identify suitable trade-offs. While preliminary, the results are encouraging enough for the computer-assisted design and development of sustainable insect production chains. Future works will take into account more extensive models, able to simulate scenarios in different European countries, and include parts of the chain such as transportation of goods to and from the production facilities.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {352–-355},
numpages = {4},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@inproceedings{mouhrim2022evolutionary,
author = {Mouhrim, Nisrine and Tonda, Alberto and Rodr\'{\i}guez-Guerra, Itzel and Kraneveld, Aletta D. and Rincon, Alejandro Lopez},
title = {An Evolutionary Approach to the Discretization of Gene Expression Profiles to Predict the Severity of COVID-19},
year = {2022},
isbn = {9781450392686},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3520304.3529001},
doi = {10.1145/3520304.3529001},
abstract = {In this work, we propose to use a state-of-the-art evolutionary algorithm to set the discretization thresholds for gene expression profiles, using feedback from a classifier in order to maximize the accuracy of the predictions based on the discretized gene expression levels, while at the same time minimizing the number of different profiles obtained, to ease the understanding of the expert. The methodology is applied to a dataset containing COVID-19 patients that developed either mild or severe symptoms. The results show that the evolutionary approach performs better than a traditional discretization based on statistical analysis, and that it does preserve the sense-making necessary for practitioners to trust the results.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {731–-734},
numpages = {4},
location = {Boston, Massachusetts},
series = {GECCO '22}
}

@incollection{tonda2022intercontinental,
year = {2022},
month = apr,
publisher = {EUROSIS},
author = {Alberto Tonda and Christian Reynolds and Nisrine Mouhrim and Rallou Thomopoulos},
title = {An Intercontinental Machine Learning Analysis of Factors Explaining Consumer Awareness About Food Risk},
booktitle = {Proceedings of FoodSIM 2022, 12th bi-annual International Conference on Modelling and Simulation in Food Engineering},
abstract = {This paper investigates to what extent food safety is perceived as a concern at the household level in different countries. It aims to identify the factors that best explain food safety concern, among the various food-related questions asked through a survey. To do so, a machine learning approach is used. The results show that the most significant explanatory variables of safety concern are the estimates of carbon footprints and calories associated with food products and primarily with beef and chicken meat. These results tend to indicate that people who are most concerned about food safety are also those who are best aware of environmental and nutritional impacts of food.}
}

@incollection{barbiero2022predictable,
  doi = {10.1007/978-3-030-95467-3_29},
  url = {https://doi.org/10.1007/978-3-030-95467-3_29},
  year = {2022},
  publisher = {Springer International Publishing},
  pages = {399--412},
  author = {Pietro Barbiero and Giovanni Squillero and Alberto Tonda},
  title = {Predictable Features Elimination: An Unsupervised Approach to Feature Selection},
  booktitle = {Machine Learning,  Optimization,  and Data Science},
  abstract = {We propose an unsupervised, model-agnostic, wrapper method for feature selection. We assume that if a feature can be predicted using the others, it adds little information to the problem, and therefore could be removed without impairing the performance of whatever model will be eventually built. The proposed method iteratively identifies and removes predictable, or nearly-predictable, redundant features, allowing to trade-off complexity with expected quality. The approach do not rely on target labels nor values, and the model used to identify predictable features is not related to the final use of the feature set. Therefore, it can be used for supervised, unsupervised, or semi-supervised problems, or even as a safe, pre-processing step to improve the quality of the results of other feature selection techniques. Experimental results against state-of-the-art feature-selection algorithms show satisfying performance on several non-trivial benchmarks.}
}

@incollection{zhang2023mapelites,
    doi = {10.1007/978-3-031-29573-7_6},
    url = {https://doi.org/10.1007/978-3-031-29573-7_6},
    year = {2023},
    publisher = {Springer Nature Switzerland},
    pages = {84--100},
    author = {Hengzhe Zhang and Qi Chen and Alberto Tonda and Bing Xue and Wolfgang Banzhaf and Mengjie Zhang},
    title = {{MAP}-Elites with~Cosine-Similarity for~Evolutionary Ensemble Learning},
    booktitle = {Lecture Notes in Computer Science},
    abstract = {Evolutionary ensemble learning methods with Genetic Programming have achieved remarkable results on regression and classification tasks by employing quality-diversity optimization techniques like MAP-Elites and Neuro-MAP-Elites. The MAP-Elites algorithm uses dimensionality reduction methods, such as variational auto-encoders, to reduce the high-dimensional semantic space of genetic programming to a two-dimensional behavioral space. Then, it constructs a grid of high-quality and diverse models to form an ensemble model. In MAP-Elites, however, variational auto-encoders rely on Euclidean space topology, which is not effective at preserving high-quality individuals. To solve this problem, this paper proposes a principal component analysis method based on a cosine-kernel for dimensionality reduction. In order to deal with unbalanced distributions of good individuals, we propose a zero-cost reference points synthesizing method. Experimental results on 108 datasets show that combining principal component analysis using a cosine kernel with reference points significantly improves the performance of the MAP-Elites evolutionary ensemble learning algorithm.}
}

@InProceedings{das2023direct,
author="Das, Soumita
and Singha, Bijita
and Tonda, Alberto
and Biswas, Anupam",
editor="Shakya, Subarna
and Papakostas, George
and Kamel, Khaled A.",
title="Direct Comparative Analysis of Nature-Inspired Optimization Algorithms on Community Detection Problem in Social Networks",
booktitle="Mobile Computing and Sustainable Informatics",
year="2023",
publisher="Springer Nature Singapore",
address="Singapore",
pages="629--642",
abstract="Nature-inspired optimization Algorithms (NIOAs) are nowadays a popular choice for community detection in social networks. Community detection problem in social network is treated as an optimization problem, where the objective is to either maximize the connection within the community or minimize connections between the communities. To apply NIOAs, either of the two, or both objectives are explored. Since NIOAs mostly exploit randomness in their strategies, it is necessary to analyze their performance for specific applications. In this paper, NIOAs are analyzed for the community detection problem. A direct comparison approach is followed to perform the pairwise comparison of NIOAs. The performance is measured in terms of five scores designed based on the prasatul matrix and also with average isolability. Three widely used real-world social networks and four NIOAs are considered for analyzing the quality of communities generated by NIOAs.",
isbn="978-981-99-0835-6"
}

@InProceedings{rojasvelazquez2023multiobjective,
author="Rojas-Velazquez, David
and Tonda, Alberto
and Rodriguez-Guerra, Itzel
and Kraneveld, Aletta D.
and Lopez-Rincon, Alejandro",
editor="Correia, Jo{\~a}o
and Smith, Stephen
and Qaddoura, Raneem",
title="Multi-objective Evolutionary Discretization of Gene Expression Profiles: Application to COVID-19 Severity Prediction",
booktitle="Applications of Evolutionary Computation",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="703--717",
abstract="Machine learning models can use information from gene expressions in patients to efficiently predict the severity of symptoms for several diseases. Medical experts, however, still need to understand the reasoning behind the predictions before trusting them. In their day-to-day practice, physicians prefer using gene expression profiles, consisting of a discretized subset of all data from gene expressions: in these profiles, genes are typically reported as either over-expressed or under-expressed, using discretization thresholds computed on data from a healthy control group. A discretized profile allows medical experts to quickly categorize patients at a glance. Building on previous works related to the automatic discretization of patient profiles, we present a novel approach that frames the problem as a multi-objective optimization task: on the one hand, after discretization, the medical expert would prefer to have as few different profiles as possible, to be able to classify patients in an intuitive way; on the other hand, the loss of information has to be minimized. Loss of information can be estimated using the performance of a classifier trained on the discretized gene expression levels. We apply one common state-of-the-art evolutionary multi-objective algorithm, NSGA-II, to the discretization of a dataset of COVID-19 patients that developed either mild or severe symptoms. The results show not only that the solutions found by the approach dominate traditional discretization based on statistical analysis and are more generally valid than those obtained through single-objective optimization, but that the candidate Pareto-optimal solutions preserve the sense-making that practitioners find necessary to trust the results.",
isbn="978-3-031-30229-9"
}

@inproceedings{tonda2023towards,
author = {Tonda, Alberto and Alvarez, Isabelle and Martin, Sophie and Squillero, Giovanni and Lutton, Evelyne},
title = {Towards Evolutionary Control Laws for Viability Problems},
year = {2023},
isbn = {9798400701191},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3583131.3590415},
doi = {10.1145/3583131.3590415},
abstract = {The mathematical theory of viability, developed to formalize problems related to natural and social phenomena, investigates the evolution of dynamical systems under constraints. A main objective of this theory is to design control laws to keep systems inside viable domains. Control laws are traditionally defined as rules, based on the current position in the state space with respect to the boundaries of the viability kernel. However, finding these boundaries is a computationally expensive procedure, feasible only for trivial systems. We propose an approach based on Genetic Programming (GP) to discover control laws for viability problems in analytic form. Such laws could keep a system viable without the need of computing its viability kernel, facilitate communication with stakeholders, and improve explainability. A candidate set of control rules is encoded as GP trees describing equations. Evaluation is noisy, due to stochastic sampling: initial conditions are randomly drawn from the state space of the problem, and for each, a system of differential equations describing the system is solved, creating a trajectory. Candidate control laws are rewarded for keeping viable as many trajectories as possible, for as long as possible. The proposed approach is evaluated on established benchmarks for viability and delivers promising results.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1464–1472},
numpages = {9},
location = {Lisbon, Portugal},
series = {GECCO '23}
}


@InProceedings{barbiero2023interpretable,
  title = 	 {Interpretable Neural-Symbolic Concept Reasoning},
  author =       {Barbiero, Pietro and Ciravegna, Gabriele and Giannini, Francesco and Espinosa Zarlenga, Mateo and Magister, Lucie Charlotte and Tonda, Alberto and Lio, Pietro and Precioso, Frederic and Jamnik, Mateja and Marra, Giuseppe},
  booktitle = 	 {Proceedings of the 40th International Conference on Machine Learning},
  pages = 	 {1801--1825},
  year = 	 {2023},
  editor = 	 {Krause, Andreas and Brunskill, Emma and Cho, Kyunghyun and Engelhardt, Barbara and Sabato, Sivan and Scarlett, Jonathan},
  volume = 	 {202},
  series = 	 {Proceedings of Machine Learning Research},
  month = Jul,
  dates = 	 {23--29 Jul},
  publisher =    {PMLR},
  url = {https://proceedings.mlr.press/v202/barbiero23a.html},
  abstract = 	 {Deep learning methods are highly accurate, yet their opaque decision process prevents them from earning full human trust. Concept-based models aim to address this issue by learning tasks based on a set of human-understandable concepts. However, state-of-the-art concept-based models rely on high-dimensional concept embedding representations which lack a clear semantic meaning, thus questioning the interpretability of their decision process. To overcome this limitation, we propose the Deep Concept Reasoner (DCR), the first interpretable concept-based model that builds upon concept embeddings. In DCR, neural networks do not make task predictions directly, but they build syntactic rule structures using concept embeddings. DCR then executes these rules on meaningful concept truth degrees to provide a final interpretable and semantically-consistent prediction in a differentiable manner. Our experiments show that DCR: (i) improves up to +25\% w.r.t. state-of-the-art interpretable concept-based models on challenging benchmarks (ii) discovers meaningful logic rules matching known ground truths even in the absence of concept supervision during training, and (iii), facilitates the generation of counterfactual examples providing the learnt rules as guidance.}
}

@inproceedings{barbiero2023interpretableNeSy,
  title = 	 {Interpretable Neural-Symbolic Concept Reasoning},
  author =       {Barbiero, Pietro and Ciravegna, Gabriele and Giannini, Francesco and Espinosa Zarlenga, Mateo and Magister, Lucie Charlotte and Tonda, Alberto and Lio, Pietro and Precioso, Frederic and Jamnik, Mateja and Marra, Giuseppe},
  booktitle = 	 {Proceedings of the Proceedings of the 17th International Workshop on Neural-Symbolic Learning and Reasoning},
  pages = 	 {422--423},
  year = 	 {2023},
  editor = 	 {d'Avila Garcez, Artur S. and Besold, Tarek R. and Gori, Marco and Jiménez-Ruiz, Ernesto},
  volume = 	 {202},
  series = 	 {CEUR Workshop Proceedings},
  month = Jul,
  dates = 	 {3--5 Jul},
  publisher =    {CEUR},
  url = {https://ceur-ws.org/Vol-3432/paper41.pdf},
  issn = {1613-0073}
}

@inproceedings{lopezrincon2023bayesian,
  title = {Bayesian Optimization for the Inverse Problem in Electrocardiography},
  booktitle = {2023 IEEE Symposium Series on Computational Intelligence (SSCI)},
  publisher = {IEEE},
  doi={10.1109/SSCI52147.2023.10371791},
  url={https://ieeexplore.ieee.org/document/10371791},
  author = {Lopez-Rincon,  Alejandro and Rojas-Velazquez,  David and Garssen,  Johan and van der Laan,  Sander W. and Oberski,  Daniel and Tonda,  Alberto},
  year = {2023},
  month = dec,
  abstract = {The inverse problem in electrocardiography is an illposed problem where the objective is to reconstruct the electrical activity of the epicardial surface of the heart, given the electrical activity on the thorax’ surface. In the forward problem, the electrical propagation from heart to thorax is modeled by the volume conductor equation with Dirichlet boundary conditions in the heart’s surface, and null flux coming from the thorax. The inverse problem, however, does not have a unique solution. In order to find solutions for the inverse problem, techniques such as Tikhonov regularization are classically used, but they often deliver unrealistic solutions. As an alternative, we propose a novel approach, where a fixed solution of the volume conductor model with a source in a forward scheme is used to solve the inverse problem. The unknown values for parameters of the fixed solution can be found using optimization techniques. Due to the characteristics of the problem, where each single evaluation of the cost function is expensive, we use a specialized CMA-ES-based Bayesian optimization technique, that can deliver good results even with a reduced number of function evaluations. Experiments show that the proposed approach can deliver improved results for in-silico simulations.}
}

@inproceedings{calabrese2024towards,
author = {Calabrese, Andrea and Quer, Stefano and Squillero, Giovanni and Tonda, Alberto},
title = {Towards an Evolutionary Approach for Exploting Core Knowledge in Artificial Intelligence},
year = {2024},
isbn = {9798400704956},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
doi = {10.1145/3638530.3654230},
url = {https://doi.org/10.1145/3638530.3654230},
abstract = {This paper presents a proof of concept for a novel evolutionary methodology inspired by core knowledge. This theory describes human cognition as a small set of innate abilities combined through compositionality. The proposed approach generates predictive descriptions of the interaction between elements in simple 2D videos. It exploits well-known strategies, such as image segmentation, object detection, simple laws of physics (kinematics and dynamics), and evolving rules, including high-level classes and their interactions. The experimental evaluation focuses on two classic video games, Pong and Arkanoid. Analyzing a small number of raw video frames, the methodology identifies objects, classes, and rules, creating a compact, high-level, predictive description of the interactions between the elements in the videos.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {259–262},
numpages = {4},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{chen2024multiobjective,
author = {Chen, Mathilde and Makowski, David and Tonda, Alberto},
title = {Multi-Objective Optimization for Large-scale Allocation of Soybean Crops},
year = {2024},
isbn = {9798400704949},
url = {https://doi.org/10.1145/3638529.3654026},
doi = {10.1145/3638529.3654026},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {The optimal allocation of crops to different parcels of land is a problem of paramount practical importance, not only to improve production, but also to address the challenges posed by climate change. However, this optimization problem is inherently complex, characterized by a vast search space that renders traditional optimization techniques impractical without oversimplified assumptions. Compounding this challenge, climate change introduces conflicting objectives, as solutions aiming to just maximize total yield may be more susceptible to extreme weather events, and thus obtain more unpredictable year-by-year outcomes. In order to tackle this complex optimization problem, we propose a multi-objective approach, simultaneously maximizing the overall yield, minimizing the year-on-year yield variance, and minimizing the total cultivated surface. The approach exploits an established multi-objective evolutionary algorithm, and employs a machine learning model able to predict yield from weather and soil conditions, trained on historical data, making it possible to tackle allocation problems of large size. An experimental evaluation focusing on the allocation of soybean crops in the European continent for the years 2000-2023 shows that the proposed methodology is able to identify different trade-offs between the conflicting objectives, that an expert analysis later reveals to be realistic and meaningful for driving stakeholder decisions.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference},
pages = {1174–1182},
numpages = {9},
location = {Melbourne, VIC, Australia},
series = {GECCO '24}
}

@inproceedings{squillero2024byron,
author = {Squillero, Giovanni and Tonda, Alberto and Masetta, Dimitri and Sacchet, Marco},
title = {Byron: A Fuzzer for Turing-complete Test Programs},
year = {2024},
isbn = {9798400704956},
url = {https://doi.org/10.1145/3638530.3664136},
doi = {10.1145/3638530.3664136},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
abstract = {This paper describes Byron, an evolutionary fuzzer of assembly-language programs for the test and verification of programmable devices. Candidate solutions are internally encoded as typed, directed multigraphs, that is, graphs where multiple edges can connect the same pair of vertexes, with an added layer that defines the type of information vertexes can hold, and constraints the possible kinds of edges. Multiple genetic operators and a self-adaptation mechanism make the tool ready to tackle industrial problems.},
booktitle = {Proceedings of the Genetic and Evolutionary Computation Conference Companion},
pages = {1691–1694},
numpages = {4},
location = {Melbourne, VIC, Australia},
series = {GECCO '24 Companion}
}

@inproceedings{giannini2024categorical,
  author       = {Francesco Giannini and Stefano Fioravanti and Pietro Barbiero and Alberto Tonda and Pietro Li{\`{o}} and Elena Di Lavore},
  editor       = {Luca Longo and Sebastian Lapuschkin and Christin Seifert},
  title        = {Categorical Foundation of Explainable {AI:} {A} Unifying Theory},
  booktitle    = {Explainable Artificial Intelligence - Second World Conference, xAI 2024, Valletta, Malta, July 17-19, 2024, Proceedings, Part {III}},
  series       = {Communications in Computer and Information Science},
  volume       = {2155},
  pages        = {185--206},
  publisher    = {Springer},
  year         = {2024},
  url          = {https://doi.org/10.1007/978-3-031-63800-8\_10},
  doi          = {10.1007/978-3-031-63800-8\_10},
}

@inproceedings{ruedaarango2024image,
  author={Rueda-Arango, Y. Dianey and Rojas-Velazquez, David and Gorelova, Aleksandra V. and Garssen, Johan and Tonda, Alberto and Lopez-Rincon, Alejandro},
  booktitle={2024 16th International Conference on Human System Interaction (HSI)}, 
  title={Image Generation with Interactive Evolutionary System using Bayesian Optimization}, 
  year={2024},
  pages={1-7},
  doi={10.1109/HSI61632.2024.10613596},
  url={https://ieeexplore.ieee.org/document/10613596},
  abstract={Interactive Evolutionary Systems (IES) can generate several designs based on a handful of input parameters. Never-theless, the choice of the parameters is an open problem and it is limited to a few evaluations as they require human input. As a solution, Bayesian Optimization (BO) can be used to tune IES parameters. BO is a statistical method that efficiently models and optimizes expensive black-box derivative-free functions in few evaluations. In the context of creative IES, such as image generators, it can be used in conjunction with user preferences to optimize a complex-structured input space, such as variations of artistic images with uniqueness and creativity that follow the original concept and the artistic intention. Therefore, for this objective, we propose an implementation of BOIES with a metric based on user preferences that interactively evaluates a batch of images to evolve a set of parameters in Stable Diffusion to create variations with a given human-made artwork. Our results proved better than baseline, and against generated images using Neural Style Transfer (NST). The resulting images were consistent in terms of uniqueness, quality, and following a given concept.}
}

@inproceedings{rojasvelazquez2024machinelearning,
  author={Rojas-Velazquez, David and Kidwai, Sarah and de Vries, Luciënne and Tözsér, Péter and Valencia-Rosado, Luis Oswaldo and Garssen, Johan and Tonda, Alberto and Lopez-Rincon, Alejandro},
  booktitle={2024 16th International Conference on Human System Interaction (HSI)}, 
  title={Machine-Learning Analysis of mRNA: An Application to Inflammatory Bowel Disease}, 
  year={2024},
  volume={},
  number={},
  pages={1-7},
  doi={10.1109/HSI61632.2024.10613568},
  url={https://ieeexplore.ieee.org/document/10613568},
  abstract={Inflammatory Bowel Disease (IBD), that includes Crohn's disease (CD) and Ulcerative Colitis (UC), is a global health concern due to the increasing number of cases. Diagnosing IBD is a challenging task due to a considerable number of clinical factors. Delayed or inaccurate IBD diagnosis can worsen the disease and complicate achieving remission, therefore, early diagnosis and prompt treatment are crucial. In this study, we adapted a methodology to analyze 16s rRNA (18,758 features) to analyze mRNA (54,675 features) that consists of three phases: 1) preprocessing, 2) feature selection, and 3) testing. We applied this methodology for analyzing mRNA datasets from the Gene Expression Omnibus (GEO) repository, aiming to discover possible biomarkers for IBD diagnosis. We experimented with three datasets, using one dataset for feature (gene) selection and we tested the results in the other two. We compared results with those obtained from other feature selection methods, such as the F-score-based K-Best and random selection. The Area Under the Curve (AUC) was used to measure the diagnostic accuracy and as a metric to compare results between the methodology and other feature selection methods. The Matthews Correlation Coefficient (MCC) was used as an additional metric to evaluate the performance of the methodology and for comparison with other feature selection methods.}
}

